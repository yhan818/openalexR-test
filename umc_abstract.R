# For Saleh Ahlam 
# Author: Yan Han with assistant ChatGPT 4o


# install.packages("readr")  # Uncomment if you don't have the readr package
# install.packages("httr")
# install.packages("jsonlite")

library(readr)
library(httr)
library(jsonlite)
library(dplyr)

# Step 1: Read the CSV file
setwd("/home/yhan/Documents/openalexR-test/")
file_path <- "2024-10-29.csv"  # Replace with your actual file path
data <- read_csv(file_path)

# Step 2: Extract the "DOI" column and remove empty cells
doi_column <- data$DOI[!is.na(data$DOI) & data$DOI != ""]

# Example list of DOIs (replace this with your DOI vector from the CSV)
doi_column <- doi_column[1:100]
print(doi_column)

doi_column <- c("10.1007/s11069-020-03875-3", "10.1111/ssqu.12699")

# A more flexible pattern for DOIs
doi_pattern <- "^10\\.\\d{4,9}/.+$"

# Identify which DOIs are invalid
rm(invalid_dois)
invalid_dois <- doi_column[!grepl(doi_pattern, doi_column)]

# Print the invalid DOIs
print(invalid_dois)


get_doi_metadata_org <- function(doi) {
  # Format the URL for the CrossRef API request
  url <- paste0("https://api.crossref.org/works/", doi)
  
  # Make the GET request
  response <- GET(url)
  
  # Check if the request was successful
  if (status_code(response) == 200) {
    # Parse the JSON content
    data <- fromJSON(content(response, "text", encoding = "UTF-8"))
    # Return the metadata part of the response
    return(data$message)
  } else {
    warning(paste("Failed to fetch metadata for DOI:", doi))
    return(NULL)
  }
}


get_doi_metadata <- function(doi) {
  # Format the URL for the CrossRef API request
  url <- paste0("https://api.crossref.org/works/", doi)
  
  attempt <- 1
  max_attempts <- 3
  
  while (attempt <= max_attempts) {
    response <- tryCatch({
      GET(url)
    }, error = function(e) {
      message("Error fetching DOI:", doi, " - ", e)
      return(NULL)
    })
    # Check if the response was successful and not NULL
    if (!is.null(response) && status_code(response) == 200) {
      data <- fromJSON(content(response, "text", encoding = "UTF-8"))
      return(data$message)
    } else if (!is.null(response) && status_code(response) != 200) {
      warning(paste("Failed to fetch metadata for DOI:", doi, "Status code:", status_code(response)))
      return(NULL)
    } else {
      message(paste("Retrying DOI:", doi, " - Attempt", attempt))
      attempt <- attempt + 1
      Sys.sleep(1)  # Short delay before retrying
    }
  }
  
  message("Failed to retrieve metadata for DOI after ", max_attempts, " attempts: ", doi)
  return(NULL)
}

# Create an empty list to store metadata
metadata_list <- list()
metadata_list <- lapply(doi_column, get_doi_metadata)

str(metadata_list[[1]])  # Check the structure of the first element

# Convert metadata_list into a structured data frame
metadata_df <- bind_rows(lapply(metadata_list, function(x) {
  if (is.list(x) && !is.null(x)) {
    tryCatch({
      data.frame(
        doi = ifelse(!is.null(x$DOI), x$DOI, NA),
        title = ifelse(!is.null(x$title), x$title, NA),
        abstract = ifelse(!is.null(x$abstract), x$abstract, NA),  # Corrected abstract field
        author = ifelse(!is.null(x$author),
                        paste(x$author$family, collapse = ", "),
                        NA),
        published_date = ifelse(!is.null(x$`published-print`$`date-parts`),
                                paste(x$`published-print`$`date-parts`[[1]], collapse = "-"),
                                NA),
        journal = ifelse(!is.null(x$`short-container-title`), x$`short-container-title`, NA),
        stringsAsFactors = FALSE
      )
    }, error = function(e) {
      data.frame(
        doi = NA, title = NA, abstract = NA, author = NA, published_date = NA, journal = NA
      )
    })
  } else {
    NULL
  }
}))

# Print the resulting data frame
print(metadata_df)


# Print the resulting data frame
print(metadata_df)
