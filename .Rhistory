oa_entities()
options (openalexR.mailto="yhan@arizona.edu")
getwd()
setwd("/home/yhan/Documents/openalexR-test")
### Test data
test_data_UAL_authors     <- c("Yan Han", "Ellen Dubinski", "Fernando Rios", "Ahlam Saleh")
test_data_COM_authors     <- c("Phillip Kuo", "Bekir Tanriover", "Ahlam Saleh")
test_data_COM_Tucson_authors <- c("Che Carrie Liu", "Robert M. Aaronson", "Alexa Aasronson", "Mohammed Abbas", "")
test_data_science_authors <- c("Marek Rychlik", "Ali Bilgin", "Beichuan Zhang")
test_data_ischool_authors <- c("Hong Cui")
test_data_others          <- c("Leila Hudson", "Mona Hymel")
test_data_not_updated_authors <-c("Karen Padilla", "Haw-chih Tai")
test_data_affiliation <- c("University of Arizona")
test_data_year <- c("2022", "2021", "2020", "2012")
# Test works
works_from_dois <- oa_fetch(entity = "works", doi = c("https://doi.org/10.1093/ofid/ofac186", "https://doi.org/10.1007/s11192-013-1221-3"),  verbose = TRUE)
### Testing three datasets citations recall and precision using one article (published in 2022)
### OpenAlex: Precision
### OpenCitaitons: Precision 100%. Recall: 2/3
### Google scholar: Precision 100%. Recall 100%
works_from_dois <- oa_fetch(entity = "works", doi = c("https://doi.org/10.6017/ital.v40i1.12553"),  verbose = TRUE)
works_from_dois$cited_by_api_url
works_from_dois$ids
# All locations:
# count: 14903 (2024-07-11)
UA_host_all_location <- oa_fetch (
entity = "works",
locations.source.host_organization = "https://openalex.org/I138006243",
#count_only = TRUE
)
View(source_counts_df)
# common libraries
library(openalexR)
packageVersion("openalexR")
library(dplyr)
library(ggplot2)
library(knitr)
library(testthat)
library(readr)
citation("openalexR")
# check to see if openAlexR has the latest entities in OpenAlex (OpenAlex updated its data model(Entities) in June 2023)
# Before April 2023: they are [1] "works"        "authors"      "venues"       "institutions" "concepts"
# If not, need to use openalexR developer's version
oa_entities()
options (openalexR.mailto="yhan@arizona.edu")
getwd()
setwd("/home/yhan/Documents/openalexR-test")
### Test data
test_data_UAL_authors     <- c("Yan Han", "Ellen Dubinski", "Fernando Rios", "Ahlam Saleh")
test_data_COM_authors     <- c("Phillip Kuo", "Bekir Tanriover", "Ahlam Saleh")
test_data_COM_Tucson_authors <- c("Che Carrie Liu", "Robert M. Aaronson", "Alexa Aasronson", "Mohammed Abbas", "")
test_data_science_authors <- c("Marek Rychlik", "Ali Bilgin", "Beichuan Zhang")
test_data_ischool_authors <- c("Hong Cui")
test_data_others          <- c("Leila Hudson", "Mona Hymel")
test_data_not_updated_authors <-c("Karen Padilla", "Haw-chih Tai")
test_data_affiliation <- c("University of Arizona")
test_data_year <- c("2022", "2021", "2020", "2012")
# Best OA location. find out host organization.
# count: 8394 (2024-07-11)
# This fetch will take a few minutes. So be patient .
UA_host_best_location <- oa_fetch(
entity = "works",
# UA campus repository ID does not work as a filter
best_oa_location.source.host_organization = "https://openalex.org/I138006243",
# If only need count, uncomment the below line for a quick run.
count_only = TRUE
# If only need some samples. using the below line.
# options = list(sample = 100, seed = 1)
)
# Primary_location.source.host_organization.
# count: 24 (2024-07-11)
UA_host2 <- oa_fetch (
entity = "works",
primary_location.source.host_organization = "https://openalex.org/I138006243",
count_only = TRUE
)
############### Use campus repository source ID.
# no result using UA campus repository source ID.
UA_host5 <- oa_fetch (
entity = "works",
best_oa_location.source.host_organization = "https://openalex.org/S2764879211",
count_only = TRUE
)
UA_host6 <- oa_fetch (
entity = "works",
locations.source.host_organization = "https://openalex.org/S2764879211",
count_only = TRUE
)
# Filter the dataframe to get all rows where "so" is "journal of range management" (JRM) (case insenstive)
df_jrm <- subset(UA_host_all_location, grepl("journal of range management", so, ignore.case = TRUE))  #4,183
df_rem <- subset(UA_host_all_location, grepl("Range Ecology", so, ignore.case = TRUE)) # 432
# Count the number of occurrences of each unique value in the "source" column using dplyr
source_counts_df <- UA_host_all_location %>%
count(so, sort = TRUE)
# Display the dataframe with counts
# JRM/REM:  4183+836 (3991 + 804 for best_oa)
# Rangelands: 782 (685 for best_oa)
# NA: 384
print(source_counts_df)
#### Example 1: More like openalex pulled directly from crossref.
###  Campus repo:
doi <- "10.2458/v24i1.22003"
metadata <- get_doi_metadata(doi)
if (!is.null(metadata)) {
print(metadata)
} else {
print("No metadata found for the given DOI.")
}
library(rcrossref)
library (httr)
library(jsonlite)
# Function to get metadata for a DOI
get_doi_metadata <- function(doi) {
url <- paste0("https://api.crossref.org/works/", doi)
response <- GET(url)
if (status_code(response) == 200) {
metadata <- content(response, as = "text", encoding = "UTF-8")
metadata <- fromJSON(metadata, flatten = TRUE)
return(metadata$message)
} else {
message("Error retrieving metadata: ", status_code(response))
return(NULL)
}
}
#### Example 1: More like openalex pulled directly from crossref.
###  Campus repo:
doi <- "10.2458/v24i1.22003"
metadata <- get_doi_metadata(doi)
if (!is.null(metadata)) {
print(metadata)
} else {
print("No metadata found for the given DOI.")
}
View(metadata)
### Example 3:
# https://doi.org/10.1038/ng.3667"
doi <- "https://doi.org/10.1038/ng.3667"
metadata <- get_doi_metadata(doi)
if (!is.null(metadata)) {
print(metadata)
} else {
print("No metadata found for the given DOI.")
}
View(metadata)
ls
### 1.2 Getting all the works based on the institution ROR and publication date. It takes longer time.
# see above for the running time
org_works_2019 <-oa_fetch(
entity="works",
institutions.ror=c("03m2x1q45"),
from_publication_date ="2019-01-01",
to_publication_date = "2019-12-31"
)
library(openalexR)
packageVersion("openalexR")
install.packages("openalexR")
library(openalexR)
packageVersion("openalexR")
remotes::install_github("ropensci/openalexR", force=TRUE)
library(openalexR)
packageVersion("openalexR")
library(dplyr)
library(tidyverse)
library(writexl)
# free unused obj to manage memory
gc()
rm(list=ls())
gc()
options("max.print" = 100000)
options (openalexR.mailto="yhan@arizona.edu")
getwd()
setwd("/home/yhan/Documents/openalexR-test/")
org_works_2021 <- readRDS("../org_works_2021.rds")
org_works <- org_works_2021
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Route 2: Getting author's data?
###### change this line only to update the right dataset.
org_works_ref <- org_works$referenced_works
# There are NA references. So we need to remove them.
# This na_indices include type: article, books, errata, letter, and other types
na_indices <- which(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(org_works_ref) * 100
# Remove duplicate rows from the data frame
unique_org_works <- unique(org_works)
org_works_ref <- unique(org_works_ref) # this actually also remove NA lists.
# Filter the rows where $reference_works is NA and $type is "article"
works_na_referenced_works <- org_works %>%
filter(is.na(referenced_works) & type == "article")
# rm(org_works_ref_combined)
org_works_ref_combined <- unlist(org_works_ref, use.names = FALSE)
org_works_ref_combined <- org_works_ref_combined[!is.na(org_works_ref_combined)]  # Remove NA values
### 2.21 finding these duplicates, which mean the duplicates have been cited multiple times
# (probably more important to have these journals subscribed!)
# cited more: ~20% - 25%  (2019, 2020, 2021, 2022, 2023 UArizona data)
org_works_ref_more_cited <- org_works_ref_combined[duplicated(org_works_ref_combined)]
org_works_ref_unique <- org_works_ref_combined[!duplicated(org_works_ref_combined)]
##### 3. From authors' DF.
# Flattening authors fields from the DF (multiple authors per work).
# 426,000 obs (multiple authors) from 50,400 obs (works)
org_works_since <- org_works
#########################
# Ensure oa_fetch() is receiving the correct input and create a new dataframe for results.
works_cited <- data.frame()
works_cited2 <-data.frame()
#num_of_works <-10000
num_of_works <- length (org_works_ref_combined)
#### Step 1: Re-generate a new row if it matches (meaning; cited multiple times.)
works_cited_final <- works_cited
works_cited_final <- readRDS("../works_cited_final_2021.rds")
# Filter rows where issn_l is neither NA nor an empty string
articles_cited <- works_cited_final[!is.na(works_cited_final$issn_l) & works_cited_final$issn_l != "", ]
nrow(articles_cited)
#############################
# Filter records where type is "article" (excluding conference paper etc )
# 2023: 226,947
non_articles_cited <- articles_cited[articles_cited$type != "article", ] # review, letter, editorial
articles_cited <- articles_cited[articles_cited$type == "article", ]
# Truncate strings in all character columns to 32,767 characters
non_articles_cited <- non_articles_cited %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
write_xlsx(non_articles_cited, "citations/non_articles_cited_2022.xlsx")
write_xlsx(non_articles_cited, "citations/non_articles_cited_2021.xlsx")
# Empty or NULL records
count_null_empty_id <- sum(is.na(articles_cited$id) | trimws(articles_cited$id) == "")
count_null_empty_id
# publisher: host_organization
unique_publishers <- unique(articles_cited$host_organization)
# number of publishers: ~1,600
num_unique_publishers <- length(unique_publishers)
# list top 50 publishers
print(unique_publishers[1:50])
# 2022: 3,312 NA / 323,221
# 2021: 3,687 NA / 341,738
# 2020: 4,039 NA / 382,495
num_na <- sum(is.na(articles_cited$host_organization))
# Dealing with "NA" data in "host_organization" field.
# 1. First, showing all NA publisher: meaning publisher info is not available.
publisher_NA <- articles_cited[articles_cited$host_organization == "NA", ]
publisher_NA_id <-unique(publisher_NA$id)
# Check if any row in the df 'publisher_NA' contains a non-missing value in the "issn_l" column
publisher_NA_with_issn <- publisher_NA[!is.na(publisher_NA$`issn_l`) & publisher_NA$`issn_l` != "", ]
print(publisher_NA_with_issn)
# Extract unique ISSNs from the 'issn_l' column: 1235 unique issns
# 2023: 1,236 / 3,489 NA
# 2022: 1,110 / 3,312 NA
# 2021: 1,204 / 3,687 NA
# 2020: 1,737 / 4,039 NA
unique_issn <- unique(publisher_NA$`issn_l`)
print(unique_issn)
# Not using unnect() because it flattens out every article per author, which creates a lot of duplicated info
library(jsonlite)
# Convert the 'author' dataframe to JSON for each row
publisher_NA <- publisher_NA %>%
mutate(author = sapply(author, function(x) toJSON(x)))
# Truncate only strings that exceed Excel's 32,767 character limit
publisher_NA <- publisher_NA %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
publisher_name <- "Microbiology society"
publisher_microbiology <- articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
publisher_elsevier <- articles_cited[grepl("Elsevier BV", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_springer <- articles_cited[tolower(articles_cited$host_organization) == tolower("Springer Science+Business Media"), ]
publisher_plos <- articles_cited[grepl("Public Library of Science", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_aaas <- articles_cited[grepl("American Association for the Advancement of Science", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_nature <- articles_cited[grepl("Nature Portfolio", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_cdc <- articles_cited[grepl("Centers for Disease Control and Prevention", articles_cited$host_organization, ignore.case = TRUE), ]
# University of Arizona
publisher_ua <- articles_cited[grepl("University of Arizona", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_uap <- articles_cited[grepl("University of Arizona Press", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_aps <- articles_cited[grepl("American Phytopathological Society", articles_cited$host_organization, ignore.case = TRUE), ]
# IWA: cited (yyyy): 19 (2019), 34 (2020), 21 (2021), 19 (2022),
publisher_iwa <- articles_cited[grepl("IWA Publishing", articles_cited$host_organization, ignore.case = TRUE), ]
View(publisher_aps)
non-articles <- works_cited_final[!is.na(works_cited_final$issn_l) | works_cited_final$issn_l != "", ]
non_articles <- works_cited_final[!is.na(works_cited_final$issn_l) | works_cited_final$issn_l != "", ]
non_articles_cited <- works_cited_final[!is.na(works_cited_final$issn_l) | works_cited_final$issn_l != "", ]
# Get rows that do NOT match the articles_cited condition
non_articles_cited <- works_cited_final[is.na(works_cited_final$issn_l) | works_cited_final$issn_l == "", ]
clear(non_articles)
rm(non_articles)
article_cited_index <- !is.na(works_cited_final$issn_l) & works_cited_final$issn_l != ""
# Subset articles_cited
articles_cited <- works_cited_final[article_cited_index, ]
# Subset non_articles_cited (the rest)
non_articles_cited <- works_cited_final[!article_cited_index, ]
# Filter rows where issn_l is neither NA nor an empty string
articles_cited <- works_cited_final[!is.na(works_cited_final$issn_l) & works_cited_final$issn_l != "", ]
nrow(articles_cited)
#############################
# Filter records where type is "article" (excluding conference paper etc )
# 2023: 226,947
articles_cited <- articles_cited[articles_cited$type == "article", ]
# Subset articles_cited
articles_cited <- works_cited_final[article_cited_index, ]
#############################
# Filter records where type is "article" (excluding conference paper etc )
# 2023: 226,947
articles_cited2 <- articles_cited[articles_cited$type == "article", ]
diff(articles_cited,articles_cited2)
difference_df1_df2 <- setdiff(article_cited$id, articles_cited2$id)
difference_df1_df2 <- setdiff(articles_cited$id, articles_cited2$id)
head(difference_df1_df2)
view(https://openalex.org/W1982579644)
type_journal_works_cited_index <- !is.na(works_cited_final$issn_l) & works_cited_final$issn_l != ""
# Subset articles_cited
type_journal_cited <- works_cited_final[type_journal_index, ]
# Subset non_articles_cited (the rest)
type_non_journal_works_cited <- works_cited_final[!type_journal_works_cited_index, ]
# Subset articles_cited
type_journal_cited <- works_cited_final[type_journal_works_index, ]
# Subset articles_cited
type_journal_works_cited <- works_cited_final[type_journal_works_index, ]
# Subset articles_cited
type_journal_works_cited <- works_cited_final[type_journal_works_cited_index, ]
# Subset non_articles_cited (the rest)
type_non_journal_works_cited <- works_cited_final[!type_journal_works_cited_index, ]
articles_cited <- type_journal_works_cited[type_non_journal_works_cited$type == "article", ]
articles_cited <- type_journal_works_cited[type_journal_works_cited$type == "article", ]
articles_cited2 <- type_non_journal_works_cited[type_non_journal_works_cited$type == "article", ]
View(articles_cited2)
#############################
# Filter records where type is "article" (excluding conference paper etc )
# 2023: 226,947
rm(articles_cited)
#############################
# Filter records where type is "article" (excluding conference paper etc )
# 2023: 226,947
rm(articles_cited2)
journal_articles_cited <- type_journal_works_cited[type_journal_works_cited$type == "article", ]
journal_non_article_cited <- type_journal_works_cited[type_journal_works_cited$type != "article", ]
journal_non_articles_cited <- type_journal_works_cited[type_journal_works_cited$type != "article", ]
non_journal_articles_cited <- type_non_journal_works_cited[type_non_journal_works_cited$type == "article", ]
non_journal_non_articles_cited <- type_non_journal_works_cited[type_non_journal_works_cited$type != "article", ]
# Empty or NULL records
count_null_empty_id <- sum(is.na(journal_articles_cited$id) | trimws(journal_articles_cited$id) == "")
count_null_empty_id
# publisher: host_organization
unique_publishers <- unique(journal_articles_cited$host_organization)
# number of publishers: ~1,600
num_unique_publishers <- length(unique_publishers)
# list top 50 publishers
print(unique_publishers[1:50])
# 2022: 3,312 NA / 323,221
# 2021: 3,687 NA / 341,738
# 2020: 4,039 NA / 382,495
num_na <- sum(is.na(journal_articles_cited$host_organization))
# Replace NA values and empty strings with "NA"
journal_articles_cited$host_organization[is.na(journal_articles_cited$host_organization) | trimws(journal_articles_cited$host_organization) == ""] <- "NA"
# Dealing with "NA" data in "host_organization" field.
# 1. First, showing all NA publisher: meaning publisher info is not available.
publisher_NA <- journal_articles_cited[journal_articles_cited$host_organization == "NA", ]
publisher_NA_id <-unique(publisher_NA$id)
# Check if any row in the df 'publisher_NA' contains a non-missing value in the "issn_l" column
publisher_NA_with_issn <- publisher_NA[!is.na(publisher_NA$`issn_l`) & publisher_NA$`issn_l` != "", ]
print(publisher_NA_with_issn)
# Extract unique ISSNs from the 'issn_l' column: 1235 unique issns
# 2023: 1,236 / 3,489 NA
# 2022: 1,110 / 3,312 NA
# 2021: 1,204 / 3,687 NA
# 2020: 1,737 / 4,039 NA
unique_issn <- unique(publisher_NA$`issn_l`)
print(unique_issn)
# Not using unnect() because it flattens out every article per author, which creates a lot of duplicated info
library(jsonlite)
# Convert the 'author' dataframe to JSON for each row
publisher_NA <- publisher_NA %>%
mutate(author = sapply(author, function(x) toJSON(x)))
# Truncate only strings that exceed Excel's 32,767 character limit
publisher_NA <- publisher_NA %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
publisher_name <- "Microbiology society"
publisher_microbiology <- journal_articles_cited[grepl(publisher_name, journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_elsevier <- journal_articles_cited[grepl("Elsevier BV", journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_springer <- journal_articles_cited[tolower(journal_articles_cited$host_organization) == tolower("Springer Science+Business Media"), ]
publisher_plos <- journal_articles_cited[grepl("Public Library of Science", journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_aaas <- journal_articles_cited[grepl("American Association for the Advancement of Science", journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_nature <- journal_articles_cited[grepl("Nature Portfolio", journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_cdc <- journal_articles_cited[grepl("Centers for Disease Control and Prevention", journal_articles_cited$host_organization, ignore.case = TRUE), ]
# University of Arizona
publisher_ua <- journal_articles_cited[grepl("University of Arizona", journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_uap <- journal_articles_cited[grepl("University of Arizona Press", journal_articles_cited$host_organization, ignore.case = TRUE), ]
# Need to study more.
# Emerald: cited (yyyy): 395 (2020), 257 (2021), 322 (2022), 276 (2023),
publisher_emerald <- journal_articles_cited[grepl("Emerald Publishing", journal_articles_cited$host_organization, ignore.case = TRUE), ]
# IWA: cited (yyyy): 19 (2019), 34 (2020), 21 (2021), 19 (2022),
publisher_iwa <- journal_articles_cited[grepl("IWA Publishing", journal_articles_cited$host_organization, ignore.case = TRUE), ]
# APS: cited (YYY): 159 (2021).
# Articles
publisher_aps <- journal_articles_cited[grepl("American Phytopathological Society", journal_articles_cited$host_organization, ignore.case = TRUE), ]
id_counts <-table(publisher_iwa$id)
### Cell press
publisher_cell_press <- journal_articles_cited[grepl("Cell Press", journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_cell_press_unique <- unique(publisher_cell_press)
df <-publisher_cell_press
# Use table to count occurrences of each duplicated row
row_counts <- as.data.frame(table(apply(df, 1, paste, collapse = "-")))
# IWA: cited (yyyy): 19 (2019), 34 (2020), 21 (2021), 19 (2022),
publisher_iwa <- journal_articles_cited[grepl("IWA Publishing", journal_articles_cited$host_organization, ignore.case = TRUE), ]
# APS: cited (YYY): 159 (2021).
# Articles
publisher_aps <- journal_articles_cited[grepl("American Phytopathological Society", journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_iwa2 <- journal_non_articles_cited[grepl("IWA Publishing", journal_non_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_iwa2 <- non_journal_articles_cited[grepl("IWA Publishing", non_journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_iwa2 <- non_journal_non_articles_cited[grepl("IWA Publishing", non_journal_non_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_iwa2 <- journal_non_articles_cited[grepl("IWA Publishing", journal_non_articles_cited$host_organization, ignore.case = TRUE), ]
# IWA: cited (yyyy): 19 (2019), 34 (2020), 21 (2021), 19 (2022),
publisher_iwa <- journal_articles_cited[grepl("IWA Publishing", journal_articles_cited$host_organization, ignore.case = TRUE), ]
# APS: cited (YYY): 159 (2021).
# Articles
publisher_aps <- journal_articles_cited[grepl("American Phytopathological Society", journal_articles_cited$host_organization, ignore.case = TRUE), ]
publisher_iwa2 <- type_journal_works_cited[grepl("IWA Publishing", type_journal_works_cited$host_organization, ignore.case = TRUE), ]
publisher_aps2 <- type_journal_works_cited[grepl("American Phytopathological Society", type_journal_works_cited$host_organization, ignore.case = TRUE), ]
View(publisher_aps2)
write_xlsx(publisher_aps2, "citations/publisher_aps_2021.xlsx")
publisher_aps2 <- publisher_aps2 %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
write_xlsx(publisher_aps2, "citations/publisher_journal_aps_2021.xlsx")
# APS: cited (YYY): 159 (2021).
# Articles
#publisher_aps <- journal_articles_cited[grepl("American Phytopathological Society", journal_articles_cited$host_organization, ignore.case = TRUE), ]
# All the works.
publisher_aps <- type_journal_works_cited[grepl("American Phytopathological Society", type_journal_works_cited$host_organization, ignore.case = TRUE), ]
# Non_journal: Books and other
publisher_aps2 <- type_non_journal_works_cited[grepl("American Phytopathological Society", type_non_journal_works_cited$host_organization, ignore.case = TRUE), ]
View(publisher_aps2)
publisher_aps2 <- publisher_aps2 %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
write_xlsx(publisher_aps2, "citations/publisher_aps_non_journal_2021.xlsx")
publisher_aps <- publisher_aps %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
write_xlsx(publisher_aps, "citations/publisher_aps_journal_2021.xlsx")
View(publisher_aps2)
search_string <- "https://openalex.org/W2553340359"
search_references(search_string, org_works)
#### Function: search_work_publisher():
## Search a work's publisher and output the publisher
# @return: index of the DF
search_work_publisher <- function(search_string, df) {
# Find indices where the host_organization contains the search string (case insensitive)
indices_with_string <- which(sapply(df$id, function(x) !is.na(x) && search_string %in% x))
print(df[indices_with_string, ]$host_organization)
print(indices_with_string)
return(indices_with_string)
}
# Example usage:
search_string <- "https://openalex.org/W2963276645"
result_indices <- search_work_publisher(search_string, org_works)
###############################################################
# Verify any cited work using the function search_references()
# Define the function to search for a string in the referenced_works column and print the output
##############################################3
search_references <- function(search_string, df) {
indices_with_string <- which(sapply(df$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
print(df[indices_with_string, ]$id)
}
# Example usage:
search_string <- "Emerald Publishing"
result_indices <- search_publisher(search_string, org_works)
print(result_indices)
# Example usage
search_string <- "https://openalex.org/W1604958295"
search_string <- "https://openalex.org/W1607198972"
#search_string <- "https://openalex.org/W3216054981"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
search_references(search_string, org_works)
# Test case: Cell Press(2023)
# UA authors publish in Cell Press journals
search_publisher("Cell Press", org_works)
## search these cell press journals articles do UA authors cited.
search_string <- "https://openalex.org/W2511428910"
search_string <- "https://openalex.org/W2125987139"
search_stirng <- "https://openalex.org/W2002490399"
search_references(search_string, org_works)
######################################
######################################
### Function: To count journal occurrences for a given publisher
# @param: dataframe journal_articles_cited
#          publisher_name
# return: journal and counts cited
count_journals_by_publisher <- function(journal_articles_cited, publisher_name) {
# Filter rows where host_organization matches the specified publisher
publisher1 <-  journal_articles_cited[grepl(publisher_name, journal_articles_cited$host_organization, ignore.case = TRUE), ]
# Count the occurrences of each journal under the specified publisher
journal_counts <- table(publisher1$so)
journal_counts_df <- as.data.frame(journal_counts)
return(journal_counts_df)
}
publisher_name <- "Optica Publishing Group"
publisher1 <-  journal_articles_cited[grepl(publisher_name, journal_articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(journal_articles_cited, publisher_name)
print(journal_counts_df)
publisher_name <- "American Phytopathological Society"
publisher1 <-  journal_articles_cited[grepl(publisher_name, journal_articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(journal_articles_cited, publisher_name)
print(journal_counts_df)
search_string <- "https://openalex.org/W2553340359"
search_references(search_string, org_works)
View(publisher_aps)
search_string <- "https://openalex.org/W2982145002"
search_references(search_string, org_works)
search_string <- "https://openalex.org/W3043553413"
search_references(search_string, org_works)
search_string <- "https://openalex.org/W2897271944"
search_references(search_string, org_works)
search_string <- "https://openalex.org/W1607198972"
#search_string <- "https://openalex.org/W3216054981"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
search_references(search_string, org_works)
search_string <- "https://openalex.org/W2579739711"
search_references(search_string, org_works)
