print(indices_with_string)
articles_cited[indices_with_string, ]$id
org_works[indices_with_string, ]$id
org_works[indices_with_string, ]
### origin works: test case:
# both final published version and pre-print existing: https://openalex.org/works/W4379795917 and https://openalex.org/W4319339791
search_string <- "https://openalex.org/W2128159409"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
### Article cited: test case 2: cited 6 from microbiology
indices_with_string <- which(sapply(articles_cited$id, function(x) search_string %in% x))
print(indices_with_string)
### Article cited: test case 2: cited 6 from microbiology
cited_article_indices <- which(sapply(articles_cited$id, function(x) search_string %in% x))
print(cited_article_indices)
# Publishers test case : cited 6 from microbiology
# both final published version and pre-print existing: https://openalex.org/works/W4379795917 and https://openalex.org/W4319339791
publisher_article_indicies <- which(sapply(publisher_microbiology$id, function(x) search_string %in% x))
print(publisher_article_indicies)
publisher_microbiology[indices_with_string, ]$id
publisher_microbiology[publisher_article_indicies, ]$id
search_string <- "https://openalex.org/W2017185349"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
id_counts <-table(publisher_aaas)
id_counts <-table(publisher_aaas$id)
duplicateds <- id_counts[id_counts > 10]
print(duplicates)
print(duplicateds)
search_string <- "https://openalex.org/W2083070320"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
### Article cited: test case 2: cited 6 from microbiology
cited_article_indices <- which(sapply(articles_cited$id, function(x) search_string %in% x))
print(cited_article_indices)
### Test cases for PLOS
id_counts <-table(publisher_plos$id)
duplicateds <- id_counts[id_counts > 10]
print(duplicateds)
### Test cases for PLOS
search_string <- "https://openalex.org/W2083070320"
id_counts <-table(publisher_plos$id)
duplicateds <- id_counts[id_counts > 10]
print(duplicateds)
### Test cases for PLOS
search_string <- "https://openalex.org/W2125300654"
### Find test cases from original works ID
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
install.packages("remotes")
remotes::install_github("ropensci/openalexR", force=TRUE)
library(openalexR)
library(dplyr)
library(tidyverse)
library(writexl)
# free unused obj to manage memory
gc()
rm(list=ls())
gc()
options("max.print" = 100000)
options (openalexR.mailto="yhan@arizona.edu")
getwd()
setwd("/home/yhan/Documents/openalexR-test/")
# Banner-University Medical Center Tucson. 399 works.
UAUMC.df <-oa_fetch(
entity="works",
institutions.ror=c("02xbk5j62"),
from_publication_date ="2024-01-01")
View(UAUMC.df)
### 1.1 Getting the count only. This is the quick way to find out the total number of works.
# Typically only some seconds
UAworks_count <-oa_fetch(
entity="works",
institutions.ror=c("03m2x1q45"),
from_publication_date ="2020-01-01",
to_publication_date = "2020-12-31",
count_only = TRUE
)
org_works_2022 <-oa_fetch(
entity="works",
institutions.ror=c("03m2x1q45"),
from_publication_date ="2022-01-01",
to_publication_date = "2022-12-31"
)
View(org_works_2022)
View(org_works_2022[[4]][[2]])
# org_works_2019 <- readRDS("../org_works_2019.rds")
# org_works_2020 <- readRDS("../org_works_2020.rds")
# org_works_2021 <- readRDS("../org_works_2021.rds")
# org_works_2022 <- readRDS("../org_works_2022.rds")
org_works_2023 <- readRDS("../org_works_2023.rds")
# change working data here
org_works <- org_works_2023
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Rout2: Getting author's data?
###### change this line only to update the right dataset.
org_works_ref <- org_works$referenced_works
na_indices <- which(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(org_works_ref) * 100
# Remove NA, logical(0) from list (Meaning: no references)
org_works_ref <- Filter(function(x) length(x) > 0, org_works_ref)
class(org_works_ref)
org_works_ref_combined <- unlist(org_works_ref, use.names = FALSE)
na_indices <- which(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(org_works_ref) * 100
# Remove NA, logical(0) from list (Meaning: no references)
org_works_ref <- Filter(function(x) length(x) > 0, org_works_ref)
# works_cited_final <- readRDS("../works_cited_final_2019.rds")
# works_cited_final <- readRDS("../works_cited_final_2020.rds")
# works_cited_final <- readRDS("../works_cited_final_2021.rds")
# works_cited_final <- readRDS("../works_cited_final_2022.rds")
works_cited_final <- readRDS("../works_cited_final_2023.rds")
View(works_cited_final)
articles_cited <- works_cited_final[!(is.na(works_cited_final$issn_l)), ]
articles_cited <- articles_cited[!(is.na(articles_cited$issn_l) | articles_cited$issn_l == ""), ]
nrow(articles_cited)
# Trim and normalize the host_organization column
articles_cited$host_organization <- trimws(articles_cited$host_organization)
articles_cited$issn_l <- trimws(articles_cited$issn_l)
# Empty or NULL records
count_null_empty_id <- sum(is.na(articles_cited$id) | trimws(articles_cited$id) == "")
count_null_empty_id
# publisher: host_organization
unique_publishers <- unique(articles_cited$host_organization)
# number of publishers: ~1,600
num_unique_publishers <- length(unique_publishers)
# list top 50 publishers
print(unique_publishers[1:50])
# list NULL publishers = 5%
num_na <- sum(is.na(articles_cited$host_organization))
# Replace NA values and empty strings with "NA"
articles_cited$host_organization[is.na(articles_cited$host_organization) | trimws(articles_cited$host_organization) == ""] <- "NA"
# 1. First, showing all NA publisher: meaning publisher info is not available.
publisher_NA <- articles_cited[articles_cited$host_organization == "NA", ]
publisher_NA_id <-unique(publisher_NA$id)
# Check if any 'id' values are duplicated
any_duplicated_ids <- any(duplicated(publisher_NA$id))
# Not using unnect() because it flattens out every article per author, which creates a lot of duplicated info
library(jsonlite)
# Convert the 'author' dataframe to JSON for each row
publisher_NA <- publisher_NA %>%
mutate(author = sapply(author, function(x) toJSON(x)))
# Truncate only strings that exceed Excel's 32,767 character limit
publisher_NA <- publisher_NA %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
publisher_name <- "Microbiology society"
publisher_microbiology <- articles_cited[tolower(articles_cited$host_organization) == tolower(publisher_name), ]
publisher_elsevier <- articles_cited[tolower(articles_cited$host_organization) == "elsevier bv", ]
publisher_springer <- articles_cited[tolower(articles_cited$host_organization) == tolower("Springer Science+Business Media"), ]
publisher_plos <- articles_cited[tolower(articles_cited$host_organization) == tolower("Public Library of Science"), ]
publisher_aaas <- articles_cited[tolower(articles_cited$host_organization) == tolower("American Association for the Advancement of Science"), ]
publisher_nature <- articles_cited[tolower(articles_cited$host_organization) == tolower("Nature Portfolio"), ]
publisher_cdc <- articles_cited[tolower(articles_cited$host_organization) == tolower("Centers for Disease Control and Prevention"), ]
publisher_ua <- articles_cited[tolower(articles_cited$host_organization) == tolower("University of Arizona"), ]
publisher_uap <- articles_cited[tolower(articles_cited$host_organization) == tolower("University of Arizona Press"), ]
######################################
######################################
### Function: To count journal occurrences for a given publisher
# @param: dataframe articles_cited
#          publisher_name
# return: journal and counts cited
count_journals_by_publisher <- function(articles_cited, publisher_name) {
# Filter rows where host_organization matches the specified publisher
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
# Count the occurrences of each journal under the specified publisher
journal_counts <- table(publisher1$so)
journal_counts_df <- as.data.frame(journal_counts)
return(journal_counts_df)
}
publisher_name <- "Microbiology society"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
print(journal_counts_df)
publisher_name <- "Optica Publishing Group"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
print(journal_counts_df)
publisher_name <- "Canadian Science Publishing"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
print(journal_counts_df)
# Group by 'host_organization' and count the number of articles for each publisher
publisher_ranking <- articles_cited %>%
group_by(host_organization) %>%
summarise(article_count = n()) %>%
arrange(desc(article_count))
library(ggplot2)
top_20_publishers <- publisher_ranking %>% slice(1:20)
top_20_publishers$percentage <- (top_20_publishers$article_count / sum(top_20_publishers$article_count)) * 100
top_20_publishers$host_organization <- substr(top_20_publishers$host_organization, 1, 10)
# Bar plot for top 20 publishers
ggplot(top_20_publishers, aes(x = reorder(host_organization, -article_count), y = article_count)) +
geom_bar(stat = "identity", fill = "steelblue") +
# Real number (article count) inside the bar
geom_text(aes(label = article_count), vjust = 0.5, hjust = 1.2, size = 2.5, color = "white") +
# Adjust hjust and color for positioning inside
# Percentage outside the bar
geom_text(aes(label = sprintf("(%.1f%%)", percentage)), vjust = 0.5, hjust = -0.2, size = 3) +
# Adjust hjust for positioning outside
coord_flip() +  # Flip the axis for better readability
labs(x = "Publisher", y = "Number of Articles", title = "2019 UA Top 20 Publishers (Number of Articles Cited)") +
theme_minimal() +
theme(axis.text.y = element_text(size = 7))  # Reduce font size of publisher names
view(publisher_ranking)
rank_top_cited_journals <- function(data, journal_col, top_n = 10) {
top_cited_journals <- data %>%
group_by(!!sym(journal_col)) %>%      # Group by the journal names (column provided by the user)
summarise(citation_count = n()) %>%   # Count the number of articles per journal
arrange(desc(citation_count)) %>%     # Sort by citation count in descending order
slice(1:top_n)                        # Select top 'n' journals
print(top_cited_journals, n = top_n)
}
rank_top_cited_journals(publisher_plos, "so")
rank_top_cited_journals(publisher_aaas, "so")
rank_top_cited_journals(publisher_nature, "so")
# Test case: cited 47 times in 2023
# The Gaia mission
search_string <- "https://openalex.org/W147232447"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[14,] $id
org_works[1985,] $id
org_works[5610,] $id
### Test cases for PLOS
search_string <- "https://openalex.org/W2125300654"
id_counts <-table(publisher_plos$id)
duplicateds <- id_counts[id_counts > 80]
print(duplicateds)
id_counts <-table(publisher_aaas$id)
duplicateds <- id_counts[id_counts > 10]
duplicateds <- id_counts[id_counts > 70]
print(duplicateds)
duplicateds <- id_counts[id_counts > 50]
print(duplicateds)
duplicateds <- id_counts[id_counts > 40]
print(duplicateds)
duplicateds <- id_counts[id_counts > 10]
print(duplicateds)
id_counts <-table(publisher_elsevier$id)
duplicateds <- id_counts[id_counts > 10]
print(duplicateds)
duplicateds <- id_counts[id_counts > 60]
print(duplicateds)
search_string <- "https://openalex.org/W2093274439"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
search_string <- "https://openalex.org/W2093274439"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works_2019 <- readRDS("../org_works_2019.rds")
# change working data here
org_works <- org_works_2019
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Rout2: Getting author's data?
###### change this line only to update the right dataset.
org_works_ref <- org_works$referenced_works
search_string <- "https://openalex.org/W2093274439"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
na_indices <- which(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(org_works_ref) * 100
# Remove NA, logical(0) from list (Meaning: no references)
org_works_ref <- Filter(function(x) length(x) > 0, org_works_ref)
class(org_works_ref)
org_works_ref_combined <- unlist(org_works_ref, use.names = FALSE)
org_works_ref_combined <- org_works_ref_combined[!is.na(org_works_ref_combined)]  # Remove NA values
### 2.21 finding these duplicates, which mean the duplicates have been cited multiple times
# (probably more important to have these journals subscribed!)
# cited more: ~20% - 25%  (2022, 2023 UArizona data)
org_works_ref_more_cited <- org_works_ref_combined[duplicated(org_works_ref_combined)]
### Method 2: there are different
citation_counts <- table(org_works_ref_combined)
head(citation_counts)
# Extract citations that occur more than once (i.e., duplicates)
org_works_ref_more_cited2 <- names(citation_counts[citation_counts > 50])
# Extract citations that occur more than once (i.e., duplicates)
org_works_ref_more_cited2 <- names(citation_counts[citation_counts > 80])
head(org_works_ref_more_cited2)
search_string <- "https://openalex.org/W2066340221"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[7679,] $id
org_works[5610,] $id
org_works[3540,] $id
top_20_publishers$percentage <- (top_20_publishers$article_count / sum(top_20_publishers$article_count)) * 100
top_20_publishers$host_organization <- substr(top_20_publishers$host_organization, 1, 10)
org_works[7679,] $id
top_20_publishers <- publisher_ranking %>% slice(1:20)
top_20_publishers$percentage <- (top_20_publishers$article_count / sum(top_20_publishers$article_count)) * 100
top_20_publishers$host_organization <- substr(top_20_publishers$host_organization, 1, 10)
# Calculate the percentage of the top 20 publishers over the total
total_article_count <- sum(publisher_ranking$article_count) # Total articles in all publishers
top_20_total_count <- sum(top_20_publishers$article_count)  # Total articles in top 20 publishers
# Calculate the percentage
top_20_percentage_of_total <- (top_20_total_count / total_article_count) * 100
# Print the result
print(paste("Top 20 publishers represent", round(top_20_percentage_of_total, 2), "% of the total articles."))
# Calculate the total number of articles across all publishers
total_article_count <- sum(publisher_ranking$article_count)
# Calculate the percentage for each publisher relative to the total article count
publisher_ranking <- publisher_ranking %>%
mutate(percentage = (article_count / total_article_count) * 100)
library(ggplot2)
top_20_publishers$percentage <- (top_20_publishers$article_count / total_article_count) * 100
top_20_publishers$host_organization <- substr(top_20_publishers$host_organization, 1, 10)
# Bar plot for top 20 publishers
ggplot(top_20_publishers, aes(x = reorder(host_organization, -article_count), y = article_count)) +
geom_bar(stat = "identity", fill = "steelblue") +
# Real number (article count) inside the bar
geom_text(aes(label = article_count), vjust = 0.5, hjust = 1.2, size = 2.5, color = "white") +
# Adjust hjust and color for positioning inside
# Percentage outside the bar
geom_text(aes(label = sprintf("(%.1f%%)", percentage)), vjust = 0.5, hjust = -0.2, size = 3) +
# Adjust hjust for positioning outside
coord_flip() +  # Flip the axis for better readability
labs(x = "Publisher", y = "Number of Articles", title = "2019 UA Top 20 Publishers (Number of Articles Cited)") +
theme_minimal() +
theme(axis.text.y = element_text(size = 7))  # Reduce font size of publisher names
# top 50
top_50_publishers <- publisher_ranking %>% slice(1:50)
top_50_publishers$percentage <- (top_50_publishers$article_count / total_article_count) * 100
top_50_publishers$host_organization <- substr(top_50_publishers$host_organization, 1, 10)
top_50_publishers$host_organization <- substr(top_50_publishers$host_organization, 1, 10)
top_50_total_count <- sum(top_50_publishers$article_count)  # Total articles in top 20 publishers
top_50_percentage_of_total <- (top_50_total_count / total_article_count) * 100
# Print the result
print(paste("Top 20 publishers represent", round(top_20_percentage_of_total, 2), "% of the total articles."))
print(paste("Top 50 publishers represent", round(top_50_percentage_of_total, 2), "% of the total articles."))
# top 100
top_100_publishers <- publisher_ranking %>% slice(1:100)
top_100_publishers$percentage <- (top_100_publishers$article_count / total_article_count) * 100
top_100_publishers$host_organization <- substr(top_100_publishers$host_organization, 1, 10)
top_100_total_count <- sum(top_100_publishers$article_count)
# Calculate the percentage
top_20_percentage_of_total <- (top_20_total_count / total_article_count) * 100
top_50_percentage_of_total <- (top_50_total_count / total_article_count) * 100
top__100_percentage_of_total <- (top_100_total_count / total_article_count) * 100
top_100_percentage_of_total <- (top_100_total_count / total_article_count) * 100
print(paste("Top 100 publishers represent", round(top_100_percentage_of_total, 2), "% of the total articles."))
# Check if any row in the df 'publisher_NA' contains a non-missing value in the "issn-l" column
publisher_NA_with_issn <- publisher_NA[!is.na(publisher_NA$`issn-l`) & publisher_NA$`issn-l` != "", ]
View(publisher_NA)
# Check if any row in the df 'publisher_NA' contains a non-missing value in the "issn-l" column
publisher_NA_with_issn <- publisher_NA[!is.na(publisher_NA$`issn_l`) & publisher_NA$`issn_l` != "", ]
# View the result
print(publisher_NA_with_issn)
# Extract unique ISSNs from the 'issn-l' column
unique_issn <- unique(publisher_NA$`issn-l`)
# View the unique ISSNs
print(unique_issn)
# Extract unique ISSNs from the 'issn-l' column
unique_issn <- unique(publisher_NA$`issn_l`)
# View the unique ISSNs
print(unique_issn)
# Matching ISSN with publisher
# Define the ISSN you want to search for
issn <- "1345-9678"
# Construct the CrossRef API URL for the ISSN
url <- paste0("https://api.crossref.org/journals/", issn)
# Make the API request
response <- GET(url)
library(httr)
# Make the API request
response <- GET(url)
# Parse the JSON response
data <- fromJSON(content(response, "text"))
# Extract the publisher information
publisher <- data$message$publisher
# Print the publisher
print(publisher)
# Define a list of ISSNs (replace with your actual list of 1000 ISSNs)
issn_list <- unique(publsiher_NA$'issn_l')
# Define a list of ISSNs (replace with your actual list of 1000 ISSNs)
issn_list <- unique(publisher_NA$'issn_l')
# Initialize an empty data frame to store results
results <- data.frame(issn = character(), publisher = character(), stringsAsFactors = FALSE)
# Loop through each ISSN and make the API request
for (issn in issn_list) {
# Construct the CrossRef API URL for the ISSN
url <- paste0("https://api.crossref.org/journals/", issn)
response <- GET(url) # HTTP request
# Check if the request was successful (status code 200)
if (status_code(response) == 200) {
# Parse the response from JSON
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
if (!is.null(data$message$publisher)) {
# Extract the publisher
publisher <- data$message$publisher
} else {
# If no publisher found, set it to "Publisher not found"
publisher <- "Publisher not found"
}
} else {
# Handle failed request, store status code as publisher
publisher <- paste("Failed - Status code:", status_code(response))
}
# Append the result to the data frame
results <- rbind(results, data.frame(issn = issn, publisher = publisher, stringsAsFactors = FALSE))
}
# Loop through each ISSN and make the API request
for (issn in issn_list[20,]) {
# Construct the CrossRef API URL for the ISSN
url <- paste0("https://api.crossref.org/journals/", issn)
response <- GET(url) # HTTP request
# Check if the request was successful (status code 200)
if (status_code(response) == 200) {
# Parse the response from JSON
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
if (!is.null(data$message$publisher)) {
# Extract the publisher
publisher <- data$message$publisher
} else {
# If no publisher found, set it to "Publisher not found"
publisher <- "Publisher not found"
}
} else {
# Handle failed request, store status code as publisher
publisher <- paste("Failed - Status code:", status_code(response))
}
# Append the result to the data frame
results <- rbind(results, data.frame(issn = issn, publisher = publisher, stringsAsFactors = FALSE))
}
# Loop through each ISSN and make the API request
for (issn in issn_list[1:20]) {
# Construct the CrossRef API URL for the ISSN
url <- paste0("https://api.crossref.org/journals/", issn)
response <- GET(url) # HTTP request
# Check if the request was successful (status code 200)
if (status_code(response) == 200) {
# Parse the response from JSON
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
if (!is.null(data$message$publisher)) {
# Extract the publisher
publisher <- data$message$publisher
} else {
# If no publisher found, set it to "Publisher not found"
publisher <- "Publisher not found"
}
} else {
# Handle failed request, store status code as publisher
publisher <- paste("Failed - Status code:", status_code(response))
}
# Append the result to the data frame
results <- rbind(results, data.frame(issn = issn, publisher = publisher, stringsAsFactors = FALSE))
}
# View the results
print(results)
# Optionally, write the results to a CSV file for future use
write.csv(results, "issn_publishers.csv", row.names = FALSE)
# Loop through each ISSN and make the API request
for (issn in issn_list[1:200]) {
# Construct the CrossRef API URL for the ISSN
url <- paste0("https://api.crossref.org/journals/", issn)
response <- GET(url) # HTTP request
# Check if the request was successful (status code 200)
if (status_code(response) == 200) {
# Parse the response from JSON
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
if (!is.null(data$message$publisher)) {
# Extract the publisher
publisher <- data$message$publisher
} else {
# If no publisher found, set it to "Publisher not found"
publisher <- "Publisher not found"
}
} else {
# Handle failed request, store status code as publisher
publisher <- paste("Failed - Status code:", status_code(response))
}
# Append the result to the data frame
results <- rbind(results, data.frame(issn = issn, publisher = publisher, stringsAsFactors = FALSE))
}
# View the results
print(results)
write.csv(results, "citations/issn_publishers.csv", row.names = FALSE)
View(publisher_NA)
View(org_works_2019)
print (na_indices)
# Filter the rows where $reference_works is NA and $type is "article"
filtered_df <- org_works %>%
filter(is.na(reference_works) & type == "article")
# Filter the rows where $reference_works is NA and $type is "article"
filtered_df <- org_works %>%
filter(is.na(referenced_works) & type == "article")
# View the filtered data frame
print(filtered_df)
# Filter the rows where $reference_works is NA and $type is "article"
na_df <- org_works %>%
filter(is.na(referenced_works) & type == "article")
# View the filtered data frame
print(na_df)
# Filter the rows where $reference_works is NA and $type is "article"
na_df <- org_works %>%
filter(is.na(referenced_works) & type == "article")
print(na_df)
View(na_df)
write_xlsx(works_na_referenced_works, "citations/works_na_referenced_works.xlsx")
# Year 2019: 1575 / 8848 have "NA" referenced works while $type is "article". 18%
# Year 2023: 2245 / 9384 have "NA".
# Filter the rows where $reference_works is NA and $type is "article"
works_na_referenced_works <- org_works %>%
filter(is.na(referenced_works) & type == "article")
write_xlsx(works_na_referenced_works, "citations/works_na_referenced_works.xlsx")
