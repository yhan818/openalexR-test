to_publication_date = "2021-12-31",
count_only = TRUE
)
org_works_2020 <-oa_fetch(
entity="works",
institutions.ror=c("03m2x1q45"),
from_publication_date ="2021-01-01",
to_publication_date = "2021-12-31"
)
View(org_works_2020)
org_works_2021 <- org_works_2020
# saveRDS(org_works_2019, "../org_works_2019.rds")
# saveRDS(org_works_2020, "../org_works_2020.rds")
saveRDS(org_works_2021, "../org_works_2021.rds")
org_works <- org_works_2021
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Route 2: Getting author's data?
###### change this line only to update the right dataset.
org_works_ref <- org_works$referenced_works
# Filter the rows where $reference_works is NA and $type is "article"
works_na_referenced_works <- org_works %>%
filter(is.na(referenced_works) & type == "article")
write_xlsx(works_na_referenced_works, "citations/works_2022_na_referenced_works.xlsx")
# this na_indices include type: article, books, errata, letter, and other types
na_indices <- which(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(org_works_ref) * 100
# Remove NA, logical(0) from list (Meaning: no references)
org_works_ref <- Filter(function(x) length(x) > 0, org_works_ref)
class(org_works_ref)
org_works_ref_combined <- unlist(org_works_ref, use.names = FALSE)
### 2.21 finding these duplicates, which mean the duplicates have been cited multiple times
# (probably more important to have these journals subscribed!)
# cited more: ~20% - 25%  (2019, 2020, 2021, 2022, 2023 UArizona data)
org_works_ref_more_cited <- org_works_ref_combined[duplicated(org_works_ref_combined)]
############################################################
### 2.23 For Testing purpose: Trace back from the cited article -> $referenced_works -> original published article
# Find the index of multiple samples
head(org_works$referenced_works)
head(org_works_ref_unique)
# Use sapply to find matching elements in the org_works_ref for testing.
matching_indices <- which(sapply(org_works_ref, function(x)
any(x %in% c("https://openalex.org/W1624352668", "https://openalex.org/W1548779692")))) # https://openalex.org/W1624352668 were cited on 2021 and 2023 data
print(matching_indices)
# We can see the original works for samples
org_works[2, "id"]
org_works[174, "id"]
# Test to see how many times a work is cited.
# 21 times (2020); 26 times(2022)
index <- which(org_works_ref_more_cited == "https://openalex.org/W4247665917")
print(index)
# https://openalex.org/W4247665917 were cited in 2019, 2021, 2022 and 2023 data
index <- which(org_works_ref_unique == "https://openalex.org/W4247665917")
print(index)
org_works_ref_unique[136]
# https://openalex.org/W4247665917 were cited in 2019, 2021, 2022 and 2023 data
index <- which(org_works_ref_more_cited == "https://openalex.org/W4247665917")
print(index)
org_works_ref_unique[136]
### 3.33 Testing if a cited work is found.
# Deep Learning, Nature, by Yann LeCun, Yoshua Bengio, Geoffrey Hinton. Cited by: 62,210
search_string <- "https://openalex.org/W2919115771"
result <- lapply(org_works_ref_combined, function(x) grep(search_string, x, value = TRUE))
print(result)
matches <- result[sapply(result, length) > 0]
print(matches)
indices <- which(sapply(org_works_ref_combined, function(x) any(grepl(search_string, x))))
for (i in indices) {
cat("Index:", i, "\n")
cat("Element:\n", org_works_ref_combined[[i]], "\n\n")
}
# Find it from the original article
search_string <- "https://openalex.org/W2594545996"
# this article was cited 81 times in 2019, cited 130 times in 2020, cited 26 times (2021), 52 times(2022) cited 16 times in 2023,
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
# test case 2: cited 6 from microbiology, multiple times for 2019, 2020, 2021, 2022
# both final published version and pre-print existing: https://openalex.org/works/W4379795917 and https://openalex.org/W4319339791
search_string <- "https://openalex.org/W2128159409"
# test case 2: cited 6 from microbiology, multiple times for 2019, 2020, 2021, 2022
# both final published version and pre-print existing: https://openalex.org/works/W4379795917 and https://openalex.org/W4319339791
search_string <- "https://openalex.org/W2128159409"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
#Creating an empty dataframe to store the results of the for loop.
works_cited <-data.frame()
library(data.table)
fetch_number <- 50
# num_of_works <- length (org_works_ref_unique)
num_of_works <- length (org_works_ref_combined)
time_taken <- system.time({
for(i in seq(1, num_of_works, by=fetch_number)){
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers)
works_cited<-rbind(works_cited, batch_data)
}
})
#Creating an empty dataframe to store the results of the for loop.
works_cited <-data.frame()
time_taken <- system.time({
for(i in seq(1, num_of_works, by=fetch_number)){
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers)
works_cited<-rbind(works_cited, batch_data)
}
})
org_works_ref_combined <- org_works_ref_combined[!is.na(org_works_ref_combined)]  # Remove NA values
# Ensure oa_fetch() is receiving the correct input and create a new dataframe for results.
works_cited <- data.frame()
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
# Get a batch of identifiers
batch_identifiers <- org_works_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
oa_fetch(entity = "works", identifier = batch_identifiers, output = "df")
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data)) {
works_cited <- rbind(works_cited, batch_data)
}
}
}
})
# Print total time taken
print(time_taken)
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
# Get a batch of identifiers
batch_identifiers <- org_works_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
oa_fetch(identifier = batch_identifiers)
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data)) {
works_cited <- rbind(works_cited, batch_data)
}
}
}
})
num_of_works <- 500
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
# Get a batch of identifiers
batch_identifiers <- org_works_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
oa_fetch(identifier = batch_identifiers)
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data)) {
works_cited <- rbind(works_cited, batch_data)
}
}
}
})
# Print total time taken
print(time_taken)
View(works_cited)
# Ensure oa_fetch() is receiving the correct input and create a new dataframe for results.
works_cited <- data.frame()
num_of_works <- 200
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
batch_identifiers <- org_works_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
oa_fetch(identifier = batch_identifiers)
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data)) {
works_cited <- rbind(works_cited, batch_data)
}
}
}
})
# Print total time taken
print(time_taken)
num_of_works <- length (org_works_ref_combined)
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
batch_identifiers <- org_works_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
oa_fetch(identifier = batch_identifiers)
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data)) {
works_cited <- rbind(works_cited, batch_data)
}
}
}
})
# Print total time taken
print(time_taken)
#### Step 1: Re-generate a new row if it matches (meaning; cited multiple times.)
works_cited_final <- works_cited
saveRDS(works_cited_final, "../works_cited_final_2021.rds")
articles_cited <- works_cited_final[!(is.na(works_cited_final$issn_l)), ]
articles_cited <- articles_cited[!(is.na(articles_cited$issn_l) | articles_cited$issn_l == ""), ]
nrow(articles_cited)
# Trim and normalize the host_organization column
articles_cited$host_organization <- trimws(articles_cited$host_organization)
articles_cited$issn_l <- trimws(articles_cited$issn_l)
# Empty or NULL records
count_null_empty_id <- sum(is.na(articles_cited$id) | trimws(articles_cited$id) == "")
count_null_empty_id
# publisher: host_organization
unique_publishers <- unique(articles_cited$host_organization)
# number of publishers: ~1,600
num_unique_publishers <- length(unique_publishers)
# list top 50 publishers
print(unique_publishers[1:50])
# list NULL publishers ~ 1 %
# 2022: 3,312 NA / 323,221
# 2021: 3,886 NA / 379,441
# 2020: 4,039 NA / 382,495
num_na <- sum(is.na(articles_cited$host_organization))
# Replace NA values and empty strings with "NA"
articles_cited$host_organization[is.na(articles_cited$host_organization) | trimws(articles_cited$host_organization) == ""] <- "NA"
# Dealing with "NA" data in "host_organization" field.
# 1. First, showing all NA publisher: meaning publisher info is not available.
publisher_NA <- articles_cited[articles_cited$host_organization == "NA", ]
publisher_NA_id <-unique(publisher_NA$id)
# Check if any row in the df 'publisher_NA' contains a non-missing value in the "issn_l" column
publisher_NA_with_issn <- publisher_NA[!is.na(publisher_NA$`issn_l`) & publisher_NA$`issn_l` != "", ]
print(publisher_NA_with_issn)
# Extract unique ISSNs from the 'issn_l' column: 1235 unique issns
# 2022: 1,110 / 3,312 NA
# 2021: 1,920 / 3,886 NA
# 2020: 1,737 / 4,039 NA
unique_issn <- unique(publisher_NA$`issn_l`)
print(unique_issn)
# Not using unnect() because it flattens out every article per author, which creates a lot of duplicated info
library(jsonlite)
# Convert the 'author' dataframe to JSON for each row
publisher_NA <- publisher_NA %>%
mutate(author = sapply(author, function(x) toJSON(x)))
# Truncate only strings that exceed Excel's 32,767 character limit
publisher_NA <- publisher_NA %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
publisher_name <- "Microbiology society"
publisher_microbiology <- articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
publisher_elsevier <- articles_cited[grepl("Elsevier BV", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_springer <- articles_cited[tolower(articles_cited$host_organization) == tolower("Springer Science+Business Media"), ]
publisher_plos <- articles_cited[grepl("Public Library of Science", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_aaas <- articles_cited[grepl("American Association for the Advancement of Science", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_nature <- articles_cited[grepl("Nature Portfolio", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_cdc <- articles_cited[grepl("Centers for Disease Control and Prevention", articles_cited$host_organization, ignore.case = TRUE), ]
# University of Arizona
publisher_ua <- articles_cited[grepl("University of Arizona", articles_cited$host_organization, ignore.case = TRUE), ]
publisher_uap <- articles_cited[grepl("University of Arizona Press", articles_cited$host_organization, ignore.case = TRUE), ]
# Need to study more.
# Emerald: cited (yyyy): 395 (2020), 257 (2021), 322 (2022), 276 (2023),
publisher_emerald <- articles_cited[grepl("Emerald Publishing", articles_cited$host_organization, ignore.case = TRUE), ]
# IWA: cited (yyyy): 19 (2019), 34 (2020), 21 (2021), 19 (2022),
publisher_iwa <- articles_cited[grepl("IWA Publishing", articles_cited$host_organization, ignore.case = TRUE), ]
id_counts <-table(publisher_iwa$id)
duplicateds <- id_counts[id_counts >= 1]
print(id_counts)
### Test cases for AAAS
search_string <- "https://openalex.org/W2083070320"
id_counts <-table(publisher_elsevier$id)
duplicateds <- id_counts[id_counts > 60]
print(duplicateds)
id_counts <-table(publisher_aaas$id)
duplicateds <- id_counts[id_counts > 10]
print(duplicateds)
### Test cases for PLOS
search_string <- "https://openalex.org/W2125300654"
id_counts <-table(publisher_plos$id)
duplicateds <- id_counts[id_counts > 10]
print(duplicateds)
###########################################
### Search if a publisher is in a DF
# Output the publisher
# @ return: the indices of the publisher
search_publisher <- function(publisher_string, df) {
# Find indices where the host_organization contains the publisher string (case insensitive)
indices_with_string <- which(grepl(publisher_string, df$host_organization, ignore.case = TRUE))
print(df[indices_with_string, ]$host_organization)
return(indices_with_string)
}
# Example usage:
publisher_string <- "Emerald Publishing"
result_indices <- search_publisher(publisher_string, articles_cited)
# Print the indices
print(result_indices)
#### Function: search_work_publisher():
## Search a work's publisher and output the publisher
# @return: index of the DF
search_work_publisher <- function(search_string, df) {
# Find indices where the host_organization contains the search string (case insensitive)
indices_with_string <- which(sapply(df$id, function(x) !is.na(x) && search_string %in% x))
print(df[indices_with_string, ]$host_organization)
print(indices_with_string)
return(indices_with_string)
}
# Example usage:
search_string <- "https://openalex.org/W2963276645"
result_indices <- search_work_publisher(search_string, org_works)
###############################################################
# Verify any cited work using the function search_references()
# Define the function to search for a string in the referenced_works column and print the output
##############################################3
search_references <- function(search_string, df) {
indices_with_string <- which(sapply(df$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
print(df[indices_with_string, ]$id)
}
# Example usage:
search_string <- "Emerald Publishing"
result_indices <- search_publisher(search_string, org_works)
print(result_indices)
# Example usage
search_string <- "https://openalex.org/W1604958295"
search_string <- "https://openalex.org/W1607198972"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
search_references(search_string, org_works)
### Test cases for Microbiology
# both final published version and pre-print existing: https://openalex.org/works/W4379795917 and https://openalex.org/W4319339791
# Org_works ids are: "https://openalex.org/W4379795917" "https://openalex.org/W4317888776" "https://openalex.org/W4385752148" "https://openalex.org/W4319339791" "https://openalex.org/W4323537660"
# "https://openalex.org/W4323309440"
search_string <- "https://openalex.org/W2128159409"  # Microbiology articles
search_string <- "https://openalex.org/W2017185349" # Microbiology
# Publishers test case : cited 6 from microbiology
# both final published version and pre-print existing: https://openalex.org/works/W4379795917 and https://openalex.org/W4319339791
publisher_article_indicies <- which(sapply(publisher_microbiology$id, function(x) search_string %in% x))
print(publisher_article_indicies)
publisher_microbiology[publisher_article_indicies, ]$id
# Test case: cited 47 times in 2023. Verified!
# cited 32 times (2020), 53(2022)
# The Gaia mission
search_string <- "https://openalex.org/W147232447"
# Test case: cited > 80 times in 2019. verified. 18 times in 2023
# cited 123 times (2020), 40 (2022)
# https://openalex.org/W2066340221 cited > 80 times in 2019.
search_string <- "https://openalex.org/W2066340221"
search_references(search_string, org_works)
# Test case: Emerald (2022)
search_string <- "https://openalex.org/W1998245073"
search_string <- "https://openalex.org/W2508822998" # (3 times)
search_references(search_string, org_works)
# Test case: IWA. 1 (2022)
search_string <- "https://openalex.org/W2045185088"
search_publisher("nature", org_works)
search_publisher("IWA", org_works) # UA author published in IWA in 2014. not in 2019, 2020, and 2021
search_string <- "https://openalex.org/W2130109162"
search_string <- "https://openalex.org/W1965549985"
search_references(search_string, org_works)
# https://openalex.org/W2130109162 same record, different publication date?
matches <- which(tolower(articles_cited$id) == tolower(search_string))
view(articles_cited[matches, ])
print(articles_cited$id[matches])
# Save the modified dataset to Excel
write_xlsx(publisher_NA, "citations/publisher_NA_2021.xlsx")
write_xlsx(publisher_aaas, "citations/publisher_aaas_2021.xlsx")
write_xlsx(publisher_nature, "citations/publisher_nature_2021.xlsx")
write_xlsx(publisher_plos, "citations/publisher_plos_2021.xlsx")
write_xlsx(publisher_microbiology, "citations/publisher_microbiology_2021.xlsx")
write_xlsx(publisher_emerald, "citations/publisher_emerald_2021.xlsx")
write_xlsx(publisher_iwa, "citations/publisher_iwa_2021.xlsx")
######################################
######################################
### Function: To count journal occurrences for a given publisher
# @param: dataframe articles_cited
#          publisher_name
# return: journal and counts cited
count_journals_by_publisher <- function(articles_cited, publisher_name) {
# Filter rows where host_organization matches the specified publisher
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
# Count the occurrences of each journal under the specified publisher
journal_counts <- table(publisher1$so)
journal_counts_df <- as.data.frame(journal_counts)
return(journal_counts_df)
}
publisher_name <- "Microbiology society"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
print(journal_counts_df)
publisher_name <- "Optica Publishing Group"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
print(journal_counts_df)
publisher_name <- "Canadian Science Publishing"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
print(journal_counts_df)
publisher_name <- "IWA publishing"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
print(journal_counts_df)
publisher_name <- "Emerald Publishing"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
publisher_name <- "Emerald Publishing"
publisher1 <-  articles_cited[grepl(publisher_name, articles_cited$host_organization, ignore.case = TRUE), ]
journal_counts_df <- count_journals_by_publisher(articles_cited, publisher_name)
print(journal_counts_df)
write_xlsx(journal_counts_df, "citations/publisher_emerald_2021_counts.xlsx")
search_string <- "https://openalex.org/W1484587278"
search_references(search_string, org_works)
# Group by 'host_organization' and count the number of articles for each publisher
publisher_ranking <- articles_cited %>%
group_by(host_organization) %>%
summarise(article_count = n()) %>%
arrange(desc(article_count))
# Calculate the total number of articles across all publishers
total_article_count <- sum(publisher_ranking$article_count)
# Calculate the percentage for each publisher relative to the total article count
publisher_ranking <- publisher_ranking %>%
mutate(percentage = (article_count / total_article_count) * 100)
library(ggplot2)
top_20_publishers <- publisher_ranking %>% slice(1:20)
top_20_publishers$percentage <- (top_20_publishers$article_count / total_article_count) * 100
top_20_publishers$host_organization <- substr(top_20_publishers$host_organization, 1, 10)
# top 50
top_50_publishers <- publisher_ranking %>% slice(1:50)
top_50_publishers$percentage <- (top_50_publishers$article_count / total_article_count) * 100
top_50_publishers$host_organization <- substr(top_50_publishers$host_organization, 1, 10)
# top 100
top_100_publishers <- publisher_ranking %>% slice(1:100)
top_100_publishers$percentage <- (top_100_publishers$article_count / total_article_count) * 100
top_100_publishers$host_organization <- substr(top_100_publishers$host_organization, 1, 10)
# Bar plot for top 20 publishers
ggplot(top_20_publishers, aes(x = reorder(host_organization, -article_count), y = article_count)) +
geom_bar(stat = "identity", fill = "steelblue") +
# Real number (article count) inside the bar
geom_text(aes(label = article_count), vjust = 0.5, hjust = 1.2, size = 2.5, color = "white") +
# Adjust hjust and color for positioning inside
# Percentage outside the bar
geom_text(aes(label = sprintf("(%.1f%%)", percentage)), vjust = 0.5, hjust = -0.2, size = 3) +
# Adjust hjust for positioning outside
coord_flip() +  # Flip the axis for better readability
labs(x = "Publisher", y = "Number of Articles", title = "2022 UA Top 20 Publishers (Number of Articles Cited)") +
theme_minimal() +
theme(axis.text.y = element_text(size = 7))  # Reduce font size of publisher names
# Calculate the percentage of the top 20, top 50, and top 100 publishers over the total
total_article_count <- sum(publisher_ranking$article_count) # Total articles in all publishers
top_20_total_count <- sum(top_20_publishers$article_count)
top_50_total_count <- sum(top_50_publishers$article_count)
# Bar plot for top 20 publishers
ggplot(top_20_publishers, aes(x = reorder(host_organization, -article_count), y = article_count)) +
geom_bar(stat = "identity", fill = "steelblue") +
# Real number (article count) inside the bar
geom_text(aes(label = article_count), vjust = 0.5, hjust = 1.2, size = 2.5, color = "white") +
# Adjust hjust and color for positioning inside
# Percentage outside the bar
geom_text(aes(label = sprintf("(%.1f%%)", percentage)), vjust = 0.5, hjust = -0.2, size = 3) +
# Adjust hjust for positioning outside
coord_flip() +  # Flip the axis for better readability
labs(x = "Publisher", y = "Number of Articles", title = "2021 UA Top 20 Publishers (Number of Articles Cited)") +
theme_minimal() +
theme(axis.text.y = element_text(size = 7))  # Reduce font size of publisher names
# Calculate the percentage of the top 20, top 50, and top 100 publishers over the total
total_article_count <- sum(publisher_ranking$article_count) # Total articles in all publishers
top_20_total_count <- sum(top_20_publishers$article_count)
top_50_total_count <- sum(top_50_publishers$article_count)
top_100_total_count <- sum(top_100_publishers$article_count)
# Calculate the percentage for year 2019, 2020,
# Top  20: ~75%
# Top  50: ~90%
# Top 100: ~95%
top_20_percentage_of_total <- (top_20_total_count / total_article_count) * 100
top_50_percentage_of_total <- (top_50_total_count / total_article_count) * 100
top_100_percentage_of_total <-(top_100_total_count/ total_article_count) * 100
print(paste("Top 20 publishers represent",  round(top_20_percentage_of_total, 0), "% of the total articles."))
print(paste("Top 50 publishers represent",  round(top_50_percentage_of_total, 0), "% of the total articles."))
print(paste("Top 100 publishers represent", round(top_100_percentage_of_total, 0), "% of the total articles."))
view(publisher_ranking)
search_string <- "https://openalex.org/W1988407666"
search_publisher("IWA", org_works) # UA author published in IWA in 2014. not in 2019, 2020, and 2021
search_string <- "https://openalex.org/W1988407666"
search_publisher("IWA", org_works) # UA author published in IWA in 2014. not in 2019, 2020, and 2021
search_string <- "https://openalex.org/W1988407666"
search_references(search_string, org_works)
search_string <- "https://openalex.org/W2045185088"
search_references(search_string, org_works)
