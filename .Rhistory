View(b2_works_2020)
View(b3_works_2020)
# Find duplicates between
duplicates_df1 <- b3_works_2020[duplicated(b2_works_2020), ]
duplicates_df2 <- b2_works_2020[duplicated(b3_works_2020), ]
# Use %in% to identify rows in df1 that are also present in df2
common_duplicates <- df1[b2_works_2020 %in% b3_works_2020, ]
# Use %in% to identify rows in df1 that are also present in df2
common_duplicates <- b2_works_2020[b2_works_2020 %in% b3_works_2020, ]
# Find common duplicates between two data frames
common_duplicates <- intersect(b2_works_2020[duplicated(b2_works_2020), ], b3_works_2020[duplicated(b3_works_2020), ])
# Print the common duplicate rows
print(common_duplicates)
# Assuming you have two data frames: b2_works_2020 and b3_works_2020
# Find duplicate rows in b2_works_2020 and b3_works_2020
duplicates_b2 <- b2_works_2020[duplicated(b2_works_2020), ]
duplicates_b3 <- b3_works_2020[duplicated(b3_works_2020), ]
# Merge the two data frames to find common duplicate rows
common_duplicates <- merge(duplicates_b2, duplicates_b3)
# Assuming you have two data frames: b2_works_2020 and b3_works_2020
# Find duplicate rows in b2_works_2020 and b3_works_2020
duplicates_b2 <- b2_works_2020[duplicated(b3_works_2020), ]
View(b2_works_2020)
View(b2_works_2020[[3]][[2]])
# Find rows unique to df2 (not present in df1)
unique_to_df2 <- anti_join(banner_works_2020, unique_df)
# use unique() to dedup
unique_df <- unique(banner_works_2020)
#### Merge all the units' df
banner_works_2020 <- rbind(b2_works_2020, b3_works_2020, b15_works_2020, b16_works_2020, b17_works_2020)
# use unique() to dedup
unique_df <- unique(banner_works_2020)
# Find rows unique to df2 (not present in df1)
unique_to_df2 <- anti_join(banner_works_2020, unique_df)
# Print the rows unique to df2
print(unique_to_df2)
# Continue to merge b20 - b50
banner_works_2020 <- rbind(banner_works_2020, b23_works_2020, b29_works_2020, b35_works_2020, b37_works_2020, b39_works_2020, b42_works_2020, b51_works_2020, b53_works_2020)
# This is the final
all_banner_works_2020 <- unique(banner_works_2020)
unique_to_df2 <- anti_join(banner_works_2020, all_banner_works_2020)
# Print the rows unique to df2
print(unique_to_df2)
unique_to_df2 <- anti_join(all_banner_works_2020, banner_works_2020)
# Print the rows unique to df2
print(unique_to_df2)
# Assuming you have two data frames: b2_works_2020 and b3_works_2020
# Find duplicate rows in b2_works_2020 and b3_works_2020
duplicates_b2 <- all_banner_works_2020[duplicated(banner_works_2020), ]
# Assuming you have two data frames: b2_works_2020 and b3_works_2020
# Find duplicate rows in b2_works_2020 and b3_works_2020
duplicates_b2 <- banner_works_2020[duplicated(banner_works_2020), ]
duplicates_b3 <- all_banner_works_2020[duplicated(all_banner_works_2020), ]
# Print the common duplicate rows
write_xlsx(all_banner_works_2020, "final_banner_collab_works_2020.xls")
# Print the common duplicate rows
write_xlsx(duplicates_b2, "final_banner_collab_works_2020.xls")
View(duplicates_b2)
View(duplicates_b2[[3]][[1]])
View(duplicates_b2[[3]][[2]])
View(all_banner_works_2020)
View(all_banner_works_2020[[3]][[38]])
View(all_banner_works_2020[[3]][[47]])
View(all_banner_works_2020[[3]][[50]])
View(all_banner_works_2020[[3]][[67]])
View(all_banner_works_2020[[3]][[121]])
View(all_banner_works_2020[[3]][[173]])
View(all_banner_works_2020[[3]][[192]])
View(all_banner_works_2020[[3]][[255]])
View(all_banner_works_2020[[3]][[233]])
# Use apply() and any() to check if the string is present in each row of the column
result <- apply(all_banner_works_2020, 1, function(row) any(grepl("Banner", row["author$institution_display_name"])
# Use apply() and any() to check if the string is present in each row of the column
result <- apply(all_banner_works_2020, 1, function(row) any(grepl("Banner", row["author$institution_display_name"])) )
result <- apply(all_banner_works_2020, 1, function(row) any(grepl("Banner", row["author$institution_display_name"])))
# Use sapply() to apply a function to each row and check for the string
result <- sapply(all_banner_works_2020$author, function(author_list) {
any(author_list$institution_display_name == string_to_find)
})
any(author_list$institution_display_name == "Banner")
# Use sapply() to apply a function to each row and check for the string
result <- sapply(all_banner_works_2020$author, function(author_list) {
any(author_list$institution_display_name == "Banner")
})
class(all_banner_works_2020)
class(all_banner_works_2020$author)
# Use sapply() to iterate through the list of data frames
result <- sapply(all_banner_works_2020$author, function(author_df_list) {
# Use another sapply() to iterate through the data frames in each list
sapply(author_df_list, function(author_df) {
any(author_df$institution_display_name == "Banner")
})
})
any(row["institution_display_name"] == "banner")
result <- apply(all_banner_works_2020$author, 1, function(row) {
any(row["institution_display_name"] == "banner")
})
# Assuming all_banner_works_2020$author is a data frame with an "institution_display_name" column
string_to_find <- "Banner"
# Use grepl() to check if the string is present in the "institution_display_name" column
result <- grepl(string_to_find, all_banner_works_2020$author$institution_display_name)
class(all_banner_works_2020$author$institution_display_name)
class(all_banner_works_2020$author)
View(all_banner_works_2020)
View(all_banner_works_2020[[3]][[1]])
# Assuming all_banner_works_2020$author is a list of data frames
column_name <- "institution_display_name"
# Use sapply() to check the class of the specified column in each data frame
column_classes <- sapply(all_banner_works_2020$author, function(df) {
class(df[[column_name]])
})
# Assuming all_banner_works_2020$author is a list of data frames
word_to_find <- "Banner"
# Use lapply() to search for the word in each data frame within the list
word_found_list <- lapply(all_banner_works_2020$author, function(df) {
grepl(word_to_find, df$institution_display_name)
})
View(word_found_list)
# The 'word_found_list' will contain logical vectors for each data frame indicating the word "Banner" presence
# Assuming word_found_list is a list containing logical vectors
# Check if the first logical vector contains at least one "TRUE" value
contains_true <- any(word_found_list[[1]])
contains_true_list <- sapply(word_found_list, function(vector) {
any(vector)
})
View(all_banner_works_2020)
View(all_banner_works_2020[[3]][[4]])
# The 'contains_true_list' will be a logical vector indicating whether each vector contains at least one "TRUE"
# Find the row numbers where contains_true_list is FALSE
false_rows <- which(!contains_true_list)
View(all_banner_works_2020[[3]][[5]])
View(all_banner_works_2020[[3]][[8]])
View(all_banner_works_2020[[3]][[11]])
View(b2_works_2020)
View(b2_works_2020[[3]][[1]])
View(b2_works_2020[[3]][[1]])
View(duplicate_rows)
View(duplicate_rows)
View(duplicate_rows[[3]][[2]])
View(duplicate_rows[[3]][[9]])
View(duplicate_rows[[3]][[16]])
View(duplicate_rows[[3]][[18]])
View(duplicate_rows[[3]][[19]])
View(duplicate_rows[[3]][[22]])
View(duplicate_rows[[3]][[22]])
View(duplicate_rows[[3]][[24]])
View(duplicate_rows[[3]][[24]])
View(duplicate_rows[[3]][[6]])
View(duplicate_rows[[3]][[10]])
View(duplicate_rows[[3]][[15]])
View(duplicate_rows[[3]][[18]])
View(duplicate_rows[[3]][[23]])
View(duplicate_rows[[3]][[2]])
View(duplicate_rows[[3]][[3]])
View(duplicate_rows[[3]][[4]])
View(duplicate_rows[[3]][[5]])
View(duplicate_rows[[3]][[8]])
View(duplicate_rows[[3]][[7]])
View(duplicate_rows[[3]][[9]])
View(duplicate_rows[[3]][[10]])
View(duplicate_rows[[3]][[12]])
View(all_banner_works_2020)
View(b35_works_2020)
View(b35_works_2020[[3]][[7]])
View(b35_works_2020[[3]][[30]])
b35_works_2020 <- fetch_ror_year("04gjkkf30", 2020) # 55
View(b35_works_2020)
View(b35_works_2020[[3]][[19]])
View(b35_works_2020[[3]][[16]])
View(b35_works_2020[[3]][[10]])
View(b35_works_2020[[3]][[30]])
View(b35_works_2020[[3]][[35]])
View(b35_works_2020[[3]][[30]])
View(b35_works_2020[[3]][[30]])
View(b35_works_2020[[3]][[36]])
View(b35_works_2020[[3]][[39]])
View(b35_works_2020[[3]][[41]])
View(b35_works_2020[[3]][[42]])
View(b35_works_2020[[3]][[44]])
View(b35_works_2020[[3]][[49]])
View(b35_works_2020[[3]][[55]])
View(b35_works_2020[[3]][[54]])
View(b35_works_2020[[3]][[53]])
View(b35_works_2020[[3]][[52]])
View(b39_works_2020)
View(b39_works_2020[[3]][[37]])
View(b39_works_2020[[3]][[62]])
scopus_data <- read.csv("scopus_banner_health_2020.csv")
View(scopus_data)
class(scopus_data)
View(all_banner_works_2020)
openalex_data_titles <- all_banner_works_2020$display_name
# Find common titles
common_titles <-intersect( scopus_data_titles, openalex_data_titles)
scopus_data_titles <- scopus_data$Title
openalex_data_titles <- all_banner_works_2020$display_name
# Find common titles
common_titles <-intersect( scopus_data_titles, openalex_data_titles)
# try finding alike titles
install.packages("stringdist")
library(stringdist)
# calculate Jaccard similarity
similarity <-stringdist::stringdistmatrix("scopus_data_titles", "openalex_data_titles", method="jaccard")
threshold <- 0.7
# Find
similar_pairs <-which(similarity >threshold, arr.ind=FALSE)
# Find
similar_pairs <-which(similarity >threshold, arr.ind=TRUE)
# Find
similar_pairs <-which(similarity >threshold, arr.ind=TRUE)
# calculate Jaccard similarity
similarity <-stringdist::stringdistmatrix("scopus_data_titles", "openalex_data_titles", method="jaccard")
threshold <- 0.7
# Find
similar_pairs <-which(similarity >threshold, arr.ind=TRUE)
# calculate Jaccard similarity
find_similar_strings <- function(query, string_array, threshold = 0.7) {
# Calculate Jaccard similarity between the query string and the array
similarity <- stringdist::stringdistmatrix(query, string_array, method = "jaccard")
# Find indices of similar strings
similar_indices <- which(similarity > threshold)
# Extract the similar strings from the array
similar_strings <- string_array[similar_indices]
return(similar_strings)
}
similar_string <- find_similar_strings(scopus_data_titles[1], openalex_data_titles)
print(similary_string)
similar_string <- find_similar_strings(scopus_data_titles[1], openalex_data_titles)
print(similar_string)
print(scopus_data_titles)
similar_string <- find_similar_strings(scopus_data_titles[1], openalex_data_titles)
print(similar_string)
# calculate Jaccard similarity
find_similar_strings <- function(query, string_array, threshold = 0.9) {
# Calculate Jaccard similarity between the query string and the array
similarity <- stringdist::stringdistmatrix(query, string_array, method = "jaccard")
# Find indices of similar strings
similar_indices <- which(similarity > threshold)
# Extract the similar strings from the array
similar_strings <- string_array[similar_indices]
return(similar_strings)
}
#print(scopus_data_titles)
similar_string <- find_similar_strings(scopus_data_titles[1], openalex_data_titles)
print(similar_string)
print(common_titles)
# calculate Jaccard similarity
find_similar_strings <- function(query, string_array, threshold = 0.8) {
# Calculate Jaccard similarity between the query string and the array
similarity <- stringdist::stringdistmatrix(query, string_array, method = "jaccard")
# Find indices of similar strings
similar_indices <- which(similarity > threshold)
# Extract the similar strings from the array
similar_strings <- string_array[similar_indices]
return(similar_strings)
}
similar_string <- find_similar_strings(scopus_data_titles[1], openalex_data_titles)
print(similar_string)
# Calculate Jaccard similarity between the query string and the array
similarity <- stringdist::stringdistmatrix(query, string_array, method = "cosine")
# calculate Jaccard similarity
find_similar_strings <- function(query, string_array, threshold = 0.8) {
# Calculate Jaccard similarity between the query string and the array
similarity <- stringdist::stringdistmatrix(query, string_array, method = "cosine")
# Find indices of similar strings
similar_indices <- which(similarity > threshold)
# Extract the similar strings from the array
similar_strings <- string_array[similar_indices]
return(similar_strings)
}
similar_string <- find_similar_strings(scopus_data_titles[1], openalex_data_titles)
print(similar_string)
print("scopus_data_titles[1]")
print(scopus_data_titles[1])
similar_string <- find_similar_strings(scopus_data_titles[1], openalex_data_titles)
print(similar_string)
is_present <-grepl(scopus_data_titles[1], openalex_data_titles)
if (any(is_string_present)) {
print(paste(search_string, "is found in the array."))
} else {
print(paste(search_string, "is not found in the array."))
}
is_present <-grepl(scopus_data_titles[1], openalex_data_titles)
if (any(is_string_present)) {
print(paste(search_string, "is found in the array."))
} else {
print(paste(search_string, "is not found in the array."))
}
is_string_present <-grepl(scopus_data_titles[1], openalex_data_titles)
if (any(is_string_present)) {
print(paste(search_string, "is found in the array."))
} else {
print(paste(search_string, "is not found in the array."))
}
if (any(is_string_present)) {
print("is found in the array.")
} else {
print("not found in the array.")
}
search_string_in_array <- function(search_string, string_array) {
# Use grepl() with ignore.case = TRUE to perform a case-insensitive search
is_string_present <- grepl(search_string, string_array, ignore.case = TRUE)
# If is_string_present is TRUE, the string is found; if FALSE, it's not found
if (any(is_string_present)) {
message(paste(search_string, "is found in the array (case-insensitive search)."))
return(TRUE)
} else {
message(paste(search_string, "is not found in the array (case-insensitive search)."))
return(FALSE)
}
}
count =0
for (string in scopus_data_titles) {
is_found <-search_string_in_array(string, openalex_data_titles)
if (is_found) {
count <- count+1
}
}
# Find common titles. only 136 are exactly the same
scopus_data_titles   <- tolower(scopus_data_titles)
openalex_data_titles <- tolower(openalex_data_titles)
common_titles <-intersect( scopus_data_titles, openalex_data_titles)
print(common_titles)
# we will compare the titles on the two datasets:
scopus_data_titles <- scopus_data$Title
openalex_data_titles <- all_banner_works_2020$display_name
common_titles <-intersect( scopus_data_titles, openalex_data_titles)
# Find common titles. only 141 are exactly the same
scopus_data_titles   <- tolower(scopus_data_titles)
openalex_data_titles <- tolower(openalex_data_titles)
common_titles <-intersect( scopus_data_titles, openalex_data_titles)
print(common_titles)
scopus_distinct_titles <- setdiff(common_titles, scopus_data_titles)
scopus_distinct_titles <- setdiff(scopus_data_titles, common_titles)
print(scopus_distinct_titles)
write_xlsx(scopus_distinct_titles, "scopus_distinct_title.xls")
writelines(scopus_distinct_titles, "scopus_distinct_title.txt")
writeLines(scopus_distinct_titles, "scopus_distinct_title.txt")
View(b23_works_2020)
View(uniqu_df)
View(uniqu_df)
View(unique_df)
#### Merge all the units' df
banner_works_2020 <- rbind(b2_works_2020, b3_works_2020, b15_works_2020, b16_works_2020, b17_works_2020)
# Continue to merge b20 - b50
banner_works_2020 <- rbind(banner_works_2020, b23_works_2020, b29_works_2020, b35_works_2020, b37_works_2020, b39_works_2020, b42_works_2020, b51_works_2020, b53_works_2020)
# This is the final
all_banner_works_2020 <- unique(banner_works_2020)
print(scopus_distinct_titles)
View(all_banner_works_2020)
print(common_titles)
View(all_banner_works_2020)
print(common_titles)
View(all_banner_works_2020_df)
print(scopus_distinct_titles)
View(all_banner_works_2020)
View(all_banner_works_2020)
View(all_banner_works_2020)
result111 <- apply(all_banner_works_2020, 2, function(col) grepl(search_string, col))
# [108] "27-plex tandem mass tag mass spectrometry for profiling brain proteome in alzheimer's disease"
# https://openalex.org/W3020038147
# Try grep
search_string <- "27-plex tandem mass tag mass spectrometry for profiling brain proteome in alzheimer's disease"
result111 <- apply(all_banner_works_2020, 2, function(col) grepl(search_string, col))
rows_with_match <- which(rowSums(result111) > 0)
print(rows_with_match)
# [108] "27-plex tandem mass tag mass spectrometry for profiling brain proteome in alzheimer's disease"
# https://openalex.org/W3020038147
# Try grep
search_string <- "27-plex tandem mass tag mass spectrometry for profiling brain proteome in alzheimer's disease"
result111 <- apply(all_banner_works_2020, 2, function(col) grepl(search_string, col))
rows_with_match <- which(rowSums(result111) > 0)
print(rows_with_match)
result111 <- apply(all_banner_works_2020, 2, function(col) grepl(search_string, col, ignore.case = TRUE))
rows_with_match <- which(rowSums(result111) > 0)
print(rows_with_match)
result111 <- grepl(search_string, all_banner_works_2020$display_name)
rows_with_match <- which(rowSums(result111) > 0)
rows_with_match <- which(result111)
print(rows_with_match)
result111 <- grepl(search_string, all_banner_works_2020$display_name, ignore.case = TRUE)
rows_with_match <- which(result111)
print(rows_with_match)
search_string <- "27-plex tandem mass tag"
result111 <- grepl(search_string, all_banner_works_2020$display_name, ignore.case = TRUE)
rows_with_match <- which(result111)
print(rows_with_match)
search_string <- "27-Plex Tandem Mass Tag Mass Spectrometry for Profiling Brain Proteome in Alzheimer’s Disease"
result111 <- grepl(search_string, all_banner_works_2020$display_name, ignore.case = TRUE)
rows_with_match <- which(result111)
print(rows_with_match)
# [108] "27-plex tandem mass tag mass spectrometry for profiling brain proteome in alzheimer's disease"
# https://openalex.org/W3020038147
# Try grep
search_string1 <- "27-plex tandem mass tag mass spectrometry for profiling brain proteome in alzheimer's disease"
search_string2 <- "27-plex tandem mass tag"
search_string3 <- "27-Plex Tandem Mass Tag Mass Spectrometry for Profiling Brain Proteome in Alzheimer’s Disease"
result111 <- grepl(search_string1, all_banner_works_2020$display_name, ignore.case = TRUE)
rows_with_match <- which(result111)
print(rows_with_match)
# we will compare the titles on the two datasets:
scopus_data_titles <- scopus_data$Title
openalex_data_titles <- all_banner_works_2020$display_name
# All titles are converted to lower cases and trim white space. Because if you do not do that, there will be many mis-matches.
# Find common titles. only 141 are exactly the same
scopus_data_titles   <- tolower(trimws(scopus_data_titles))
openalex_data_titles <- tolower(trimws(openalex_data_titles))
#
common_titles <-intersect( scopus_data_titles, openalex_data_titles)
print(common_titles)
# we will compare the titles on the two datasets:
scopus_data_titles <- scopus_data$Title
openalex_data_titles <- all_banner_works_2020$display_name
###
scopus_data_titles   <- clean_string(scopus_data_titles)
openalex_data_titles <- clean_string(openalex_data_titles)
common_titles <-intersect( scopus_data_titles, openalex_data_titles)
###
clean_string <- function(input_str) {
# Convert to lowercase and remove special characters and whitespace
cleaned_str <- tolower(gsub("[^A-Za-z0-9]+", "", input_str))
return(cleaned_str)
}
scopus_data_titles   <- clean_string(scopus_data_titles)
openalex_data_titles <- clean_string(openalex_data_titles)
common_titles <-intersect( scopus_data_titles, openalex_data_titles)
print(common_titles)
scopus_distinct_titles <- setdiff(scopus_data_titles, common_titles)
print(scopus_distinct_titles)
writeLines(scopus_distinct_titles, "scopus_distinct_title.txt")
# we will compare the titles on the two datasets:
scopus_data_titles <- scopus_data$Title
openalex_data_titles <- all_banner_works_2020$display_name
# All titles are converted to lower cases, trim white space and handle special characters. Because if you do not do that, there will be many mis-matches.
# cannot use tolower() and trimws() along, because of special characters like '.
# Write my own function to improve results, increasing matching of 10%. Convert to lowercase and remove special characters and whitespace
clean_string <- function(input_str) {
cleaned_str <- tolower(gsub("[^A-Za-z0-9]+", "", input_str))
return(cleaned_str)
}
scopus_data_titles_clean   <- clean_string(scopus_data_titles)
openalex_data_titles_clean <- clean_string(openalex_data_titles)
common_titles <-intersect( scopus_data_titles_clean, openalex_data_titles_clean)
print(common_titles)
distinct_titles_openalx <- setdiff( titles_openalex, titles_scopus)
# common libraries to add
library(openalexR)
library(dplyr)
library(ggplot2)
library(knitr)
library(writexl)
works_from_orcids <- oa_fetch(
entity = "works",
author.orcid = c("0000-0001-9518-2684"),
# Yan Han ORCID: 0000-0001-9518-2684; have 14 works at ORCID's website. OpenAlex does not pull works from ORCID at the moment. It pulls majorly from Microsoft academic graph
# Yan Han OpenAlex ID. https://api.openalex.org/people/A2108267685
# author.orcid = c("0000-0001-6187-6610", "0000-0002-8517-9411"),
verbose = TRUE
)
works_from_orcids |>
show_works()  |>
knitr::kable()
### Aug 2023: Yan Han: affiliation Jilin university. Wrong
##### Getting authors' info using their ORCIDs
authors_from_orcids <- oa_fetch(
entity = "authors",
orcid =  c("0000-0001-6187-6610", "0000-0002-8517-9411", "0000-0003-1613-5981", "0000-0001-9518-2684")
)
str(authors_from_orcids) # show the object
authors_from_orcids |>
show_authors() |>
knitr::kable()
#################### Author's openAlex ID ###########################
### Sep 2023: old authorID was removed.
author_from_openalex_id <-oa_fetch(entity = "author", openalex = "A4353996111" )
###################### Author's name ####################################
###  use search for fuzzy name (middle name),
###  do NOT use display_name because it requires an exact match. Often there are multiple middle names for an author
authors_from_names <- oa_fetch(entity = "author",
search = "Phillip Kuo")  ### "search" syntax allowes fuzzy search for middle name
authors_from_names
authors_from_names$id
authors_from_names$affiliation_display_name
grep("Arizona*", authors_from_names$affiliation_display_name, value=TRUE, ignore.case=TRUE)
authors_from_names |>
show_authors() |>
knitr::kable()
# All authors
org_args <- list(
entity = "authors",
last_known_institution.id = "I138006243", # University of Arizona OpenAlex ID
works_count = ">0"
)
# July 2023: 58,183 records.
# Sep 2023: 26,801 records. (Note: author disambuition system changed in Aug 2023)
do.call(oa_fetch, c(org_args, list(count_only = TRUE)))
# Download the list
all_authors <- do.call(oa_fetch, org_args) |>
show_authors() |>
knitr::kable()
show(all_authors) # already sorted by total number of works_count
# Top authors
org_args2 <- list(
entity = "authors",
last_known_institution.id = "I138006243", # University of Arizona OpenAlex ID
works_count = ">499"
)
# 72 authors
do.call(oa_fetch, c(org_args2, list(count_only = TRUE)))
top_authors <- do.call(oa_fetch, org_args) |>
show_authors() |>
knitr::kable()
