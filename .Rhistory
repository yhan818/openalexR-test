unique_to_df1 <- setdiff(df1[[id_field]], df2[[id_field]])
# IDs unique to df2
unique_to_df2 <- setdiff(df2[[id_field]], df1[[id_field]])
# --- Find IDs present in both but with different values ---
# Common IDs
common_ids <- intersect(df1[[id_field]], df2[[id_field]])
# Subset data frames to include only common IDs
df1_common <- df1[df1[[id_field]] %in% common_ids, ]
df2_common <- df2[df2[[id_field]] %in% common_ids, ]
# Sort by ID for comparison
df1_common <- df1_common[order(df1_common[[id_field]]), ]
df2_common <- df2_common[order(df2_common[[id_field]]), ]
# Find rows with differences (excluding the ID field itself)
diff_rows <- which(apply(df1_common[, colnames(df1_common) != id_field, drop = FALSE] != df2_common[, colnames(df2_common) != id_field, drop = FALSE], 1, any))
# Data frame with differences
df_diff <- df1_common[diff_rows, ]
# Add a column to indicate the source of the difference
if (nrow(df_diff) > 0) {
df_diff$diff_source <- "Both (values differ)"
}
# --- Combine all differences into a single data frame ---
# Rows unique to df1
if (length(unique_to_df1) > 0) {
df_unique_df1 <- df1[df1[[id_field]] %in% unique_to_df1, ]
df_unique_df1$diff_source <- "df1 only"
} else {
df_unique_df1 <- data.frame()
}
# Rows unique to df2
if (length(unique_to_df2) > 0) {
df_unique_df2 <- df2[df2[[id_field]] %in% unique_to_df2, ]
df_unique_df2$diff_source <- "df2 only"
} else {
df_unique_df2 <- data.frame()
}
# Combine all differences
all_diffs <- rbind(df_diff, df_unique_df1, df_unique_df2)
# --- Print the results ---
cat("IDs unique to df1:\n")
print(unique_to_df1)
cat("\nIDs unique to df2:\n")
print(unique_to_df2)
cat("\nRows with differences in common IDs:\n")
print(df_diff)
cat("\nSummary of Differences:\n")
print(table(all_diffs$diff_source))
return(all_diffs)
}
id_column_name <- "id"
compare_dfs_by_id (org_works_2023_old, org_works_2023, id_column_name)
org_works_2023$id <- as.numeric(org_works_2023$id)
all_differences <- compare_dfs_by_id(org_works_2023_old, org_works_2023, "id")
org_works_2023_old$id <- as.numeric(org_works_2023_old$id)
all_differences <- compare_dfs_by_id(org_works_2023_old, org_works_2023, "id")
org_works_2023_old <- org_works_2023_old[!is.na(as.numeric(org_works_2023_old$id)), ]
org_works_2023_old$id <- as.numeric(org_works_2023_old$id)
all_differences <- compare_dfs_by_id(org_works_2023_old, org_works_2023, "id")
org_works_2023_old <- readRDS("../org_works_2023_202410.rds")
org_works_2023_old <- org_works_2023_old[!is.na(as.numeric(org_works_2023_old$id)), ]
org_works_2023_old <- readRDS("../org_works_2023_202410.rds")
View(org_works_2023)
View(org_works_2023)
View(org_works_2023)
org_works_2023 <- readRDS("../org_works_2023.rds")
org_works_2023_old <- readRDS("../org_works_2023_202410.rds")
View(org_works_2023)
compare_dfs_by_id <- function(df1, df2, id_field) {
# Debugging: Print information about id_field as it's received
print("Inside function: id_field")
print(id_field)
print(class(id_field))
print(length(id_field))
# Check if inputs are data frames
if (!is.data.frame(df1) || !is.data.frame(df2)) {
stop("Inputs df1 and df2 must be data frames.")
}
# Check if id_field is a single string (character vector of length 1)
if (!is.character(id_field) || length(id_field) != 1) {
stop("id_field must be a single string (character vector of length 1).")
}
# Robust check for ID field existence in both data frames
if (!(id_field %in% names(df1)) || !(id_field %in% names(df2))) {
stop("ID field not found in one or both data frames.")
}
# --- Find IDs present in one DF but not the other --
# IDs unique to df1
unique_to_df1 <- setdiff(df1[[id_field]], df2[[id_field]])
# IDs unique to df2
unique_to_df2 <- setdiff(df2[[id_field]], df1[[id_field]])
# --- Find IDs present in both but with different values ---
# Common IDs
common_ids <- intersect(df1[[id_field]], df2[[id_field]])
# Subset data frames to include only common IDs
df1_common <- df1[df1[[id_field]] %in% common_ids, ]
df2_common <- df2[df2[[id_field]] %in% common_ids, ]
# Sort by ID for comparison
df1_common <- df1_common[order(df1_common[[id_field]]), ]
df2_common <- df2_common[order(df2_common[[id_field]]), ]
# Find rows with differences (excluding the ID field itself)
diff_rows <- which(apply(df1_common[, colnames(df1_common) != id_field, drop = FALSE] != df2_common[, colnames(df2_common) != id_field, drop = FALSE], 1, any))
# Data frame with differences
df_diff <- df1_common[diff_rows, ]
# Add a column to indicate the source of the difference
if (nrow(df_diff) > 0) {
df_diff$diff_source <- "Both (values differ)"
}
# --- Combine all differences into a single data frame ---
# Rows unique to df1
if (length(unique_to_df1) > 0) {
df_unique_df1 <- df1[df1[[id_field]] %in% unique_to_df1, ]
df_unique_df1$diff_source <- "df1 only"
} else {
df_unique_df1 <- data.frame()
}
# Rows unique to df2
if (length(unique_to_df2) > 0) {
df_unique_df2 <- df2[df2[[id_field]] %in% unique_to_df2, ]
df_unique_df2$diff_source <- "df2 only"
} else {
df_unique_df2 <- data.frame()
}
# Combine all differences
all_diffs <- rbind(df_diff, df_unique_df1, df_unique_df2)
# --- Print the results ---
cat("IDs unique to df1:\n")
print(unique_to_df1)
cat("\nIDs unique to df2:\n")
print(unique_to_df2)
cat("\nRows with differences in common IDs:\n")
print(df_diff)
cat("\nSummary of Differences:\n")
print(table(all_diffs$diff_source))
return(all_diffs)
}
id_column_name <- "id"
all_differences <- compare_dfs_by_id(org_works_2023_old, org_works_2023, "id")
str(org_works_2023_old)
any(is.na(org_works_2023_old))
any(is.na(org_works_2023_old$id))
any(is.na(org_works_2023$id))
id_column_name <- "id"
compare_dfs_by_id_debug(org_works_2023_old, org_works_2023, id_column_name)
compare_dfs_by_id_debug <- function(df1, df2, id_field) {
# ... (other parts of the function remain the same) ...
# --- Find IDs present in both but with different values ---
# Common IDs
common_ids <- intersect(df1[[id_field]], df2[[id_field]])
# Subset data frames to include only common IDs
df1_common <- df1[df1[[id_field]] %in% common_ids, ]
df2_common <- df2[df2[[id_field]] %in% common_ids, ]
# Sort by ID for comparison
df1_common <- df1_common[order(df1_common[[id_field]]), ]
df2_common <- df2_common[order(df2_common[[id_field]]), ]
# --- DEBUGGING: Isolate the comparison logic ---
print("Debugging apply section:")
for (i in 1:nrow(df1_common)) {
row1 <- df1_common[i, colnames(df1_common) != id_field, drop = FALSE]
row2 <- df2_common[df2_common[[id_field]] == df1_common[[id_field]][i], colnames(df2_common) != id_field, drop = FALSE]
print(paste("Comparing row:", i))
print("Row from df1_common:")
print(row1)
print("Row from df2_common:")
print(row2)
# Element-wise comparison with NA handling
mapply(function(x, y) {
if (is.na(x) && is.na(y)) {
FALSE  # Both NA is not a difference
} else if (is.na(x) || is.na(y)) {
TRUE   # One NA, one not NA is a difference
} else {
x != y   # Standard comparison
}
}, row1, row2)
}
# --- (rest of the function) ---
}
id_column_name <- "id"
compare_dfs_by_id_debug(org_works_2023_old, org_works_2023, id_column_name)
compare_id_columns <- function(df1, df2, id_column_name) {
# Check if the ID column exists in both data frames
if (!(id_column_name %in% names(df1)) || !(id_column_name %in% names(df2))) {
stop("ID column not found in one or both data frames.")
}
# Get the ID vectors
ids_df1 <- df1[[id_column_name]]
ids_df2 <- df2[[id_column_name]]
# Find unique IDs
unique_to_df1 <- setdiff(ids_df1, ids_df2)
unique_to_df2 <- setdiff(ids_df2, ids_df1)
# Print the results
cat("IDs unique to df1:\n")
print(unique_to_df1)
cat("\nIDs unique to df2:\n")
print(unique_to_df2)
# Return the results as a list
return(list(
unique_to_df1 = unique_to_df1,
unique_to_df2 = unique_to_df2
))
}
org_works_2023_old <- readRDS("../org_works_2023_202410.rds")
org_works_2023 <- readRDS("../org_works_2023.rds")
id_column <- "id"  # Set the ID column name
comparison_result <- compare_id_columns(org_works_2023_old, org_works_2023, id_column)
# Access the unique IDs from the returned list:
unique_to_df1 <- comparison_result$unique_to_df1
unique_to_df2 <- comparison_result$unique_to_df2
library(openalexR)
packageVersion("openalexR")
library(dplyr)
library(tidyverse)
library(data.table)
library(writexl)
# free unused obj to manage memory
gc()
rm(list=ls())
gc()
options("max.print" = 100000)
options (openalexR.mailto="yhan@arizona.edu")
getwd()
setwd("/home/yhan/Documents/openalexR-test/")
# Typically only some seconds
UAworks_count <-oa_fetch(
entity="works",
institutions.ror=c("03m2x1q45"),
from_publication_date ="2022-01-01",
to_publication_date = "2022-12-31",
#primary_location.source.type = "journal",
count_only = TRUE
)
org_works_2022 <- readRDS("../org_works_2022.rds")
org_works <- org_works_2022
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Route 2: Getting author's data?
###### change this line only to update the right dataset.
org_works_ref <- org_works$referenced_works
# There are NA references. So we need to remove them.
# ~14% works have no references (2021)
# This na_indices include type: article, books, errata, letter, and other types
na_indices <- which(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(org_works_ref) * 100
# Remove duplicate rows from the data frame
unique_org_works <- unique(org_works)
org_works_ref <- unique(org_works_ref) # this actually also remove NA lists.
# Filter the rows where $reference_works is NA and $type is "article"
works_na_referenced_works <- org_works %>%
filter(is.na(referenced_works) & type == "article")
# rm(org_works_ref_combined)
org_works_ref_combined <- unlist(org_works_ref, use.names = FALSE)
org_works_ref_combined <- org_works_ref_combined[!is.na(org_works_ref_combined)]  # Remove NA values
############################################################
### 2.23 For Testing purpose: Trace back from the cited article -> $referenced_works -> original published article
# Find the index of multiple samples
head(org_works$referenced_works)
head(org_works_ref_unique)
# Use sapply to find matching elements in the org_works_ref for testing.
matching_indices <- which(sapply(org_works_ref, function(x)
any(x %in% c("https://openalex.org/W1624352668", "https://openalex.org/W1548779692")))) # https://openalex.org/W1624352668 were cited on 2021 and 2023 data
print(matching_indices)
# We can see the original works for samples
org_works[2, "id"]
org_works[174, "id"]
# Test to see how many times a work is cited.
# 21 times (2020); 22 times(2021), 26 times(2022), 18 times(2023)
# https://openalex.org/W4247665917 were cited in 2019, 2021, 2022 and 2023 data
index <- which(org_works_ref_combined == "https://openalex.org/W4247665917")
print(index)
##### 3. From authors' DF.
# Flattening authors fields from the DF (multiple authors per work).
# 426,000 obs (multiple authors) from 50,400 obs (works)
org_works_since <- org_works
#####################################################
#################### 3.3 TESTING!!!#################
####################################################
# Then extract UArizona authors only
# 94,500 obs from 426,000 obs (UA authors only).
## https://openalex.org/A5033317672 Saurav Mallik (is at two affiliations for https://api.openalex.org/works/W4389611927. Harvard and University of Arizona)
### https://openalex.org/W4401226694 author Renu Malhotra has two affiliations.
oa_fetch_test1 <-oa_fetch( entity="works",  id="https://openalex.org/W4401226694")
oa_fetch_test1$author
view(oa_fetch_test1[[4]][[1]])
oa_fetch_test2 <-oa_fetch( entity="authors",  id="https://openalex.org/A5003933592")
#### This is not 100% accurate because UArizona has child organization whose ROR is associated with an article. By filtering institution_rorauthor
# to UArizona's ROR, certain articles are left out!!!
# 2024-09: I am currently working with openAlexR developers to fix this.
org_works_authors_ua <- org_works_authors%>%filter(institution_rorauthor== "https://ror.org/03m2x1q45")
### 3.33 Testing if a cited work is found.
# Deep Learning, Nature, by Yann LeCun, Yoshua Bengio, Geoffrey Hinton. Cited by: 62,210
search_string <- "https://openalex.org/W2919115771"
result <- lapply(org_works_ref_combined, function(x) grep(search_string, x, value = TRUE))
matches <- result[sapply(result, length) > 0]
indices <- which(sapply(org_works_ref_combined, function(x) any(grepl(search_string, x))))
for (i in indices) {
cat("Index:", i, "\n")
cat("Element:\n", org_works_ref_combined[[i]], "\n\n")
}
for (i in indices) {
cat("Index:", i, "\n")
cat("Element:\n", org_works_ref_combined[[i]], "\n\n")
}
# Find it from the original article
search_string <- "https://openalex.org/W2594545996"
# this article was cited 81 (2019, 130 (2020), 90 (2021), 52 (2022), 16 (2023)
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
# test case 2: cited 6 from microbiology, multiple times for 2019, 2020, 2021, 2022
# both final published version and pre-print existing: https://openalex.org/works/W4379795917 and https://openalex.org/W4319339791
search_string <- "https://openalex.org/W2128159409"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
works_cited_final <- readRDS("../works_cited_final_2022.rds")
works_cited_final <- readRDS("../works_cited_2022.rds")
library(openalexR)
packageVersion("openalexR")
library(dplyr)
library(tidyverse)
library(data.table)
library(writexl)
# free unused obj to manage memory
gc()
rm(list=ls())
gc()
options("max.print" = 100000)
options (openalexR.mailto="yhan@arizona.edu")
getwd()
setwd("/home/yhan/Documents/openalexR-test/")
# Typically only some seconds
UAworks_count <-oa_fetch(
entity="works",
institutions.ror=c("03m2x1q45"),
from_publication_date ="2021-01-01",
to_publication_date = "2021-12-31",
#primary_location.source.type = "journal",
count_only = TRUE
)
org_works_2021 <- readRDS("../org_works_2021.rds")
org_works <- org_works_2021
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Route 2: Getting author's data?
###### change this line only to update the right dataset.
org_works_ref <- org_works$referenced_works
# There are NA references. So we need to remove them.
# ~14% works have no references (2021)
# This na_indices include type: article, books, errata, letter, and other types
na_indices <- which(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(org_works_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(org_works_ref) * 100
# Remove duplicate rows from the data frame
unique_org_works <- unique(org_works)
org_works_ref <- unique(org_works_ref) # this actually also remove NA lists.
# Filter the rows where $reference_works is NA and $type is "article"
works_na_referenced_works <- org_works %>%
filter(is.na(referenced_works) & type == "article")
# rm(org_works_ref_combined)
org_works_ref_combined <- unlist(org_works_ref, use.names = FALSE)
org_works_ref_combined <- org_works_ref_combined[!is.na(org_works_ref_combined)]  # Remove NA values
# Find it from the original article
search_string <- "https://openalex.org/W2594545996"
# this article was cited 81 (2019, 130 (2020), 90 (2021), 52 (2022), 16 (2023)
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
# test case 2: cited 6 from microbiology, multiple times for 2019, 2020, 2021, 2022
# both final published version and pre-print existing: https://openalex.org/works/W4379795917 and https://openalex.org/W4319339791
search_string <- "https://openalex.org/W2128159409"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
org_works[indices_with_string, ]$id
#Creating an empty dataframe to store the results of the for loop.
works_cited <-data.frame()
#########################
# Ensure oa_fetch() is receiving the correct input and create a new dataframe for results.
works_cited <- data.frame()
works_cited2 <-data.frame()
fetch_number <- 50
#num_of_works <-1000
num_of_works <- length (org_works_ref_combined)
works_cited_final <- readRDS("../works_cited_2021.rds")
# Filter rows where issn_l is neither NA nor an empty string
issn_works_cited_index <- !is.na(works_cited_final$issn_l) & works_cited_final$issn_l != ""
# Subset
issn_works_cited <- works_cited_final[issn_works_cited_index, ]
# Subset non_articles_cited (the rest)
non_issn_works_cited <- works_cited_final[!issn_works_cited_index, ]
works_cited_final <- readRDS("../works_cited_2021.rds")
issn_works_cited_article_cited <-     issn_works_cited[issn_works_cited$type == "article", ]
issn_works_cited_non_article_cited <- issn_works_cited[issn_works_cited$type != "article", ]
non_issn_works_cited_articles <-     non_issn_works_cited[non_issn_works_cited$type == "article", ]
non_issn_works_cited_non_articles <- non_issn_works_cited[non_issn_works_cited$type != "article", ]
View(non_issn_works_cited_articles)
# Empty or NULL records
count_null_empty_id <- sum(is.na(issn_works_cited$id) | trimws(issn_works_cited$id) == "")
count_null_empty_id
# publisher: host_organization
unique_publishers <- unique(issn_works_cited$host_organization)
# number of publishers: ~1,600
num_unique_publishers <- length(unique_publishers)
# list top 50 publishers
print(unique_publishers[1:50])
# 2022: 3,312 NA / 323,221
# 2021: 3,687 NA / 341,738
# 2020: 4,039 NA / 382,495
num_na <- sum(is.na(issn_works_cited$host_organization))
# Replace NA values and empty strings with "NA"
issn_works_cited$host_organization[is.na(issn_works_cited$host_organization) | trimws(issn_works_cited$host_organization) == ""] <- "NA"
# Dealing with "NA" data in "host_organization" field.
# 1. First, showing all NA publisher: meaning publisher info is not available.
publisher_NA <- issn_works_cited[issn_works_cited$host_organization == "NA", ]
publisher_NA_id <-unique(publisher_NA$id)
# Check if any row in the df 'publisher_NA' contains a non-missing value in the "issn_l" column
publisher_NA_with_issn <- publisher_NA[!is.na(publisher_NA$`issn_l`) & publisher_NA$`issn_l` != "", ]
print(publisher_NA_with_issn)
# Extract unique ISSNs from the 'issn_l' column: 1235 unique issns
# 2023: 1,236 / 3,489 NA
# 2022: 1,110 / 3,312 NA
# 2021: 1,204 / 3,687 NA
# 2020: 1,737 / 4,039 NA
unique_issn <- unique(publisher_NA$`issn_l`)
print(unique_issn)
publisher_name <- "Microbiology society"
publisher_microbiology <- issn_works_cited[grepl(publisher_name, issn_works_cited$host_organization_name, ignore.case = TRUE), ]
publisher_bmj  <- issn_works_cited[grepl("BMJ", issn_works_cited$host_organization, ignore.case = TRUE), ]
publisher_bmj2 <- non_issn_works_cited[grepl("BMJ", non_issn_works_cited$host_organization, ignore.case = TRUE), ]
View(publisher_bmj)
###########################################
### Search if a publisher is in a DF
# Output the publisher
# @ return: the indices of the publisher
search_publisher <- function(publisher_string, df) {
# Find indices where the host_organization contains the publisher string (case insensitive)
indices_with_string <- which(grepl(publisher_string, df$host_organization, ignore.case = TRUE))
print(df[indices_with_string, ]$host_organization)
print(df[indices_with_string, ]$id)
return(indices_with_string)
}
# Example usage:
publisher_string <- "Emerald Publishing"
result_indices <- search_publisher(publisher_string, issn_works_cited)
# Print the indices
print(result_indices)
#### Function: search_work_publisher():
## Search a work's publisher and output the publisher
# @return: index of the DF
search_work_publisher <- function(search_string, df) {
# Find indices where the host_organization contains the search string (case insensitive)
indices_with_string <- which(sapply(df$id, function(x) !is.na(x) && search_string %in% x))
print(df[indices_with_string, ]$host_organization)
print(indices_with_string)
return(indices_with_string)
}
# Example usage:
search_string <- "https://openalex.org/W2963276645"
result_indices <- search_work_publisher(search_string, org_works)
###############################################################
# Verify any cited work using the function search_references()
# Define the function to search for a string in the referenced_works column and print the output
##############################################3
search_references <- function(search_string, df) {
indices_with_string <- which(sapply(df$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
print(df[indices_with_string, ]$id)
}
# 2023
search_string <- "https://openalex.org/W1967057044" # 4 times
search_string <- "https://openalex.org/W2157823046" # 7 times
search_string <- "https://openalex.org/W2034673450" # 2 times
search_references(search_string, org_works)
#
search_publisher("BMJ", org_works)
# For BMJ
publisher_bmj <- publisher_bmj %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
write_xlsx(publisher_bmj, "citations/publisher_bmj_issn_cited_2021.xlsx")
# For BMJ
publisher_bmj <- publisher_bmj %>%
mutate(across(where(is.character), ~ ifelse(nchar(.) > 32767, substr(., 1, 32767), .)))
write_xlsx(publisher_bmj, "citations/publisher_bmj_issn_cited_2021.xlsx")
######################################
######################################
### Function: To count issns occurrences for a given publisher (note: issns count is more accurate)
# @param: dataframe issns_articles_cited
#          publisher_name
# return: issns and counts cited and sorted
count_issns_by_publisher <- function(issn_works_cited, publisher_name) {
# Filter rows where host_organization matches the specified publisher
publisher1 <-  issn_works_cited[grepl(publisher_name, issn_works_cited$host_organization, ignore.case = TRUE), ]
# Count the occurrences of each journal under the specified publisher
issns_counts <- table(publisher1$so)
issns_counts_df <- as.data.frame(issns_counts)
return(issns_counts_df)
}
count_issns_by_publisher <- function(issn_works_cited, publisher_name) {
# Filter rows where host_organization matches the specified publisher
publisher1 <- issn_works_cited[grepl(publisher_name, issn_works_cited$host_organization, ignore.case = TRUE), ]
# Count the occurrences of each ISSN under the specified publisher
issns_counts <- table(publisher1$so)
issns_counts_df <- as.data.frame(issns_counts)
# Rename columns for clarity
colnames(issns_counts_df) <- c("Journal Title", "Count")
# Sort the data frame by Count in descending order
issns_counts_df <- issns_counts_df[order(issns_counts_df$Count, decreasing = TRUE), ]
return(issns_counts_df)
}
publisher_name <- "BMJ"
publisher1 <-  issn_works_cited[grepl(publisher_name, issn_works_cited$host_organization, ignore.case = TRUE), ]
issns_counts_df <- count_issns_by_publisher(issn_works_cited, publisher_name)
print(issns_counts_df)
