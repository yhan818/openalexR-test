count_only = TRUE
)
UA_host6 <- oa_fetch (
entity = "works",
locations.source.host_organization = "https://openalex.org/S2764879211",
count_only = TRUE
)
# Filter the dataframe to get all rows where "so" is "journal of range management" (JRM) (case insenstive)
df_jrm <- subset(UA_host_all_location, grepl("journal of range management", so, ignore.case = TRUE))  #4,183
df_rem <- subset(UA_host_all_location, grepl("Range Ecology", so, ignore.case = TRUE)) # 432
# Count the number of occurrences of each unique value in the "source" column using dplyr
source_counts_df <- UA_host_all_location %>%
count(so, sort = TRUE)
# Display the dataframe with counts
# JRM/REM:  4183+836 (3991 + 804 for best_oa)
# Rangelands: 782 (685 for best_oa)
# NA: 384
print(source_counts_df)
#### Example 1: More like openalex pulled directly from crossref.
###  Campus repo:
doi <- "10.2458/v24i1.22003"
metadata <- get_doi_metadata(doi)
if (!is.null(metadata)) {
print(metadata)
} else {
print("No metadata found for the given DOI.")
}
library(rcrossref)
library (httr)
library(jsonlite)
# Function to get metadata for a DOI
get_doi_metadata <- function(doi) {
url <- paste0("https://api.crossref.org/works/", doi)
response <- GET(url)
if (status_code(response) == 200) {
metadata <- content(response, as = "text", encoding = "UTF-8")
metadata <- fromJSON(metadata, flatten = TRUE)
return(metadata$message)
} else {
message("Error retrieving metadata: ", status_code(response))
return(NULL)
}
}
#### Example 1: More like openalex pulled directly from crossref.
###  Campus repo:
doi <- "10.2458/v24i1.22003"
metadata <- get_doi_metadata(doi)
if (!is.null(metadata)) {
print(metadata)
} else {
print("No metadata found for the given DOI.")
}
View(metadata)
### Example 3:
# https://doi.org/10.1038/ng.3667"
doi <- "https://doi.org/10.1038/ng.3667"
metadata <- get_doi_metadata(doi)
if (!is.null(metadata)) {
print(metadata)
} else {
print("No metadata found for the given DOI.")
}
View(metadata)
ls
### 1.2 Getting all the works based on the institution ROR and publication date. It takes longer time.
# see above for the running time
org_works_2019 <-oa_fetch(
entity="works",
institutions.ror=c("03m2x1q45"),
from_publication_date ="2019-01-01",
to_publication_date = "2019-12-31"
)
library(openalexR)
library(dplyr)
library(tidyverse)
library(writexl)
# free unused obj to manage memory
gc()
rm(list=ls())
gc()
options("max.print" = 100000)
options (openalexR.mailto="yhan@arizona.edu")
getwd()
setwd("/home/yhan/Documents/openalexR-test/")
org_works_2021 <- readRDS("../org_works_2021.rds")
org_works <- org_works_2021
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Route 2: Getting author's data?
###### change this line only to update the right dataset.
org_works_ref <- org_works$referenced_works
# rm(org_works_ref_combined)
org_works_ref_combined <- unlist(org_works_ref, use.names = FALSE)
org_works_ref_combined <- org_works_ref_combined[!is.na(org_works_ref_combined)]  # Remove NA values
##### 3. From authors' DF.
# Flattening authors fields from the DF (multiple authors per work).
# 426,000 obs (multiple authors) from 50,400 obs (works)
org_works_since <- org_works
#Creating an empty dataframe to store the results of the for loop.
works_cited <-data.frame()
fetch_number <- 100
num_of_works <- 10000
#########################
# Ensure oa_fetch() is receiving the correct input and create a new dataframe for results.
works_cited <- data.frame()
works_cited2 <-data.frame()
num_of_works <-100
num_of_works <- length (org_works_ref_combined)
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
batch_identifiers <- org_works_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
# Have to use "primary_location.source.type = journal" to filter out non-journal.
# issn_l cannot be used alone (there are book chapters which have issn per OpenAlex)
oa_fetch(identifier = batch_identifiers
, primary_location.source.type = "journal",)
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data)) {
works_cited <- rbind(works_cited, batch_data)
}
}
}
})
library(data.table)
fetch_number <- 50
# num_of_works <- length (org_works_ref_unique)
num_of_works <- length (org_works_ref_combined)
range_i <- seq(1, num_of_works, by=fetch_number)
# num_of_works <- length (org_works_ref_unique)
num_of_works <-200
range_i <- seq(1, num_of_works, by=fetch_number)
works_cited_ls <- vector("list", length = length(range_i))
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_unique[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(entity="works", identifier=batch_identifiers, output="list", primary_location.source.type = "journal",)
works_cited_ls[[idx]] <- batch_data
}
})
works_cited_ls <- vector("list", length = length(range_i))
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(entity="works", identifier=batch_identifiers, output="list", primary_location.source.type = "journal",)
works_cited_ls[[idx]] <- batch_data
}
})
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(entity="works", identifier=batch_identifiers,
output="list", primary_location.source.type = "journal",)
works_cited_ls[[idx]] <- batch_data
}
batch_data <-oa_fetch(entity="works", identifier=batch_identifiers, primary_location.source.type = "journal",
output="list", )
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal",
output="list", )
works_cited_ls[[idx]] <- batch_data
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal",
output="list", )
works_cited_ls[[idx]] <- batch_data
}
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal",
output="list", )
works_cited_ls[[idx]] <- batch_data
}
})
print(paste("fetch time: ", time_taken["elapsed"] / 60, "minutes"))
### convert list to DF with measuring the performance
time_taken2 <- system.time ({
works_cited2 <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
})
print(paste("rbind time: ", time_taken2["elapsed"] / 60, "minutes"))
#profvis({
system.time({
batch_identifiers <-org_works_ref_unique[1:num_of_works]
res <-oa_fetch(identifier=batch_identifiers,
entity = "works",
options= list(sample=fetch_number, seed=1),
output="list")
})
malaria_topic <- oa_fetch(entity = "topics", search = "malaria") %>%
filter(display_name == "Malaria") %>%
pull(id)
malaria_topic
#> [1] "https://openalex.org/T10091"
system.time({
res <- oa_fetch(
topics.id = malaria_topic,
entity = "works",
verbose = TRUE,
options = list(sample = 10000, seed = 1),
output = "list"
)
})
fetch_number <- 50
# num_of_works <- length (org_works_ref_unique)
num_of_works <-200
num_of_works <- length (org_works_ref_combined)
range_i <- seq(1, num_of_works, by=fetch_number)
works_cited_ls <- vector("list", length = length(range_i))
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal",
output="list", )
works_cited_ls[[idx]] <- batch_data
}
})
library(data.table)
fetch_number <- 50
# num_of_works <- length (org_works_ref_unique)
num_of_works <-200
range_i <- seq(1, num_of_works, by=fetch_number)
works_cited_ls <- vector("list", length = length(range_i))
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal",
output="list", )
works_cited_ls[[idx]] <- batch_data
}
})
print(paste("fetch time: ", time_taken["elapsed"] / 60, "minutes"))
### convert list to DF with measuring the performance
time_taken2 <- system.time ({
works_cited2 <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
})
View(works_cited_ls)
### convert list to DF with measuring the performance
time_taken2 <- system.time ({
works_cited2 <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
})
# Define a helper function to pad each list to have the same number of rows
pad_list <- function(lst) {
max_length <- max(sapply(lst, nrow))  # Find the maximum row length
lapply(lst, function(x) {
if (nrow(x) < max_length) {
# Add NA rows to pad to max_length
x <- rbind(x, data.table(matrix(NA, ncol = ncol(x), nrow = max_length - nrow(x))))
}
return(x)
})
}
# Pad each element in works_cited_ls to ensure they have the same row length
padded_works_cited_ls <- pad_list(works_cited_ls)
# Define a function to standardize the structure of each element in works_cited_ls
pad_list <- function(lst) {
# Find the maximum number of columns and rows
max_cols <- max(sapply(lst, ncol), na.rm = TRUE)
max_rows <- max(sapply(lst, nrow), na.rm = TRUE)
# Pad each data frame to have the max number of columns and rows
lapply(lst, function(df) {
# Ensure df has the correct number of columns
if (is.data.frame(df)) {
# Pad columns if necessary
if (ncol(df) < max_cols) {
df[(max_cols - ncol(df)):max_cols] <- NA
}
# Pad rows if necessary
if (nrow(df) < max_rows) {
df <- rbind(df, data.frame(matrix(NA, ncol = ncol(df), nrow = max_rows - nrow(df))))
}
return(df)
} else {
# Convert non-data frame elements to an empty data frame with the correct structure
return(data.frame(matrix(NA, ncol = max_cols, nrow = max_rows)))
}
})
}
# Pad each element in works_cited_ls
padded_works_cited_ls <- pad_list(works_cited_ls)
# Define a function to standardize the structure of each element in works_cited_ls
pad_list <- function(lst) {
# Find the maximum number of columns and rows
max_cols <- max(sapply(lst, ncol), na.rm = TRUE)
max_rows <- max(sapply(lst, nrow), na.rm = TRUE)
# Pad each data frame to have the max number of columns and rows
lapply(lst, function(df) {
# Ensure df has the correct number of columns
if (is.data.frame(df)) {
# Pad columns if necessary
if (ncol(df) < max_cols) {
df[(max_cols - ncol(df)):max_cols] <- NA
}
# Pad rows if necessary
if (nrow(df) < max_rows) {
df <- rbind(df, data.frame(matrix(NA, ncol = ncol(df), nrow = max_rows - nrow(df))))
}
return(df)
} else {
# Convert non-data frame elements to an empty data frame with the correct structure
return(data.frame(matrix(NA, ncol = max_cols, nrow = max_rows)))
}
})
}
# Pad each element in works_cited_ls
padded_works_cited_ls <- pad_list(works_cited_ls)
library(data.table)
# Define a function to standardize the structure of each element in works_cited_ls
pad_list <- function(lst) {
# Filter out non-data frame elements
data_frames_only <- Filter(is.data.frame, lst)
# Find the maximum number of columns and rows in the data frames
max_cols <- max(sapply(data_frames_only, ncol), na.rm = TRUE)
max_rows <- max(sapply(data_frames_only, nrow), na.rm = TRUE)
# Pad each data frame to have the max number of columns and rows
lapply(lst, function(df) {
if (is.data.frame(df)) {
# Pad columns if necessary
if (ncol(df) < max_cols) {
df[(max_cols - ncol(df)):max_cols] <- NA
}
# Pad rows if necessary
if (nrow(df) < max_rows) {
df <- rbind(df, data.frame(matrix(NA, ncol = ncol(df), nrow = max_rows - nrow(df))))
}
return(df)
} else {
# Convert non-data frame elements to an empty data frame with the correct structure
return(data.frame(matrix(NA, ncol = max_cols, nrow = max_rows)))
}
})
}
# Pad each element in works_cited_ls
padded_works_cited_ls <- pad_list(works_cited_ls)
# Define a function to standardize the structure of each element in works_cited_ls
pad_list <- function(lst) {
# Filter out non-data frame elements and any lists within lists
data_frames_only <- Filter(function(x) is.data.frame(x) && !is.list(x), lst)
# Check if data_frames_only is not empty before calculating max_cols and max_rows
if (length(data_frames_only) == 0) {
stop("No data frames found in the list.")
}
# Find the maximum number of columns and rows in the data frames
max_cols <- max(sapply(data_frames_only, ncol), na.rm = TRUE)
max_rows <- max(sapply(data_frames_only, nrow), na.rm = TRUE)
# Pad each data frame to have the max number of columns and rows
lapply(lst, function(df) {
if (is.data.frame(df)) {
# Pad columns if necessary
if (ncol(df) < max_cols) {
df[(max_cols - ncol(df)):max_cols] <- NA
}
# Pad rows if necessary
if (nrow(df) < max_rows) {
df <- rbind(df, data.frame(matrix(NA, ncol = ncol(df), nrow = max_rows - nrow(df))))
}
return(df)
} else {
# Convert non-data frame elements to an empty data frame with the correct structure
return(data.frame(matrix(NA, ncol = max_cols, nrow = max_rows)))
}
})
}
# Pad each element in works_cited_ls
padded_works_cited_ls <- pad_list(works_cited_ls)
View(works_cited_ls)
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal", )
#output="list", )
works_cited_ls[[idx]] <- batch_data
}
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal", )
#output="list", )
works_cited_ls[[idx]] <- batch_data
}
})
print(paste("fetch time: ", time_taken["elapsed"] / 60, "minutes"))
library(data.table)
fetch_number <- 50
# num_of_works <- length (org_works_ref_unique)
num_of_works <-200
range_i <- seq(1, num_of_works, by=fetch_number)
works_cited_ls <- vector("list", length = length(range_i))
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal", )
#output="list", )
works_cited_ls[[idx]] <- batch_data
}
})
print(paste("fetch time: ", time_taken["elapsed"] / 60, "minutes"))
library(data.table)
View(works_cited_ls)
time_taken2 <- system.time ({
works_cited <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
})
print(paste("rbind time: ", time_taken2["elapsed"] / 60, "minutes"))
View(works_cited)
# num_of_works <- length (org_works_ref_unique)
num_of_works <-2000
range_i <- seq(1, num_of_works, by=fetch_number)
works_cited_ls <- vector("list", length = length(range_i))
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal", )
#output="list", )
works_cited_ls[[idx]] <- batch_data
}
})
print(paste("fetch time: ", time_taken["elapsed"] / 60, "minutes"))
time_taken2 <- system.time ({
works_cited <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
})
print(paste("rbind time: ", time_taken2["elapsed"] / 60, "minutes"))
time_taken2 <- system.time ({
works_cited <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
})
print(paste("rbind time: ", time_taken2["elapsed"] / 60, "minutes"))
fetch_number <- 50
# num_of_works <- length (org_works_ref_unique)
num_of_works <-20000
range_i <- seq(1, num_of_works, by=fetch_number)
works_cited_ls <- vector("list", length = length(range_i))
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal", )
#output="list", )
works_cited_ls[[idx]] <- batch_data
}
})
print(paste("fetch time: ", time_taken["elapsed"] / 60, "minutes"))
time_taken2 <- system.time ({
works_cited <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
})
print(paste("rbind time: ", time_taken2["elapsed"] / 60, "minutes"))
View(works_cited)
search_string <- "https://openalex.org/W2090037139"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
search_references(search_string, org_works)
#### Function: search_work_publisher():
## Search a work's publisher and output the publisher
# @return: index of the DF
search_work_publisher <- function(search_string, df) {
# Find indices where the host_organization contains the search string (case insensitive)
indices_with_string <- which(sapply(df$id, function(x) !is.na(x) && search_string %in% x))
print(df[indices_with_string, ]$host_organization)
print(indices_with_string)
return(indices_with_string)
}
###############################################################
# Verify any cited work using the function search_references()
# Define the function to search for a string in the referenced_works column and print the output
##############################################3
search_references <- function(search_string, df) {
indices_with_string <- which(sapply(df$referenced_works, function(x) search_string %in% x))
print(indices_with_string)
print(df[indices_with_string, ]$id)
}
search_references(search_string, org_works)
search_string <- "https://openalex.org/W3216054981"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
search_references(search_string, org_works)
search_string <- "https://openalex.org/W1607198972"
#search_string <- "https://openalex.org/W3216054981"
indices_with_string <- which(sapply(org_works$referenced_works, function(x) search_string %in% x))
search_references(search_string, org_works)
# num_of_works <- length (org_works_ref_unique)
# num_of_works <-20000
num_of_works <- length (org_works_ref_combined)
range_i <- seq(1, num_of_works, by=fetch_number)
works_cited_ls <- vector("list", length = length(range_i))
time_taken <-system.time({
for (idx in seq_along(range_i)) {
i <- range_i[idx]
batch_identifiers <-org_works_ref_combined[i:min(i+fetch_number-1, num_of_works)]
batch_data <-oa_fetch(identifier=batch_identifiers, primary_location.source.type = "journal", )
#output="list", )
works_cited_ls[[idx]] <- batch_data
}
})
#Creating an empty dataframe to store the results of the for loop.
works_cited <-data.frame()
time_taken2 <- system.time ({
works_cited <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
})
works_cited2 <- rbindlist(works_cited_ls, use.names=TRUE, fill=TRUE)
View(works_cited2)
tail(works_cited_ls)
